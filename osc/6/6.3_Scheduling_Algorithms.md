# 6.3 Scheduling Algorithms
---

CPU scheduling은 ready queue에 있는 프로세스 중 어느 것에 CPU가 할당될지를 결정하는 문제를 다룬다. 여기에는 많은 CPU-scheduling 알고리즘이 있다. 이번 절에서 이들 중 몇 가지를 설명한다.

## 6.3.1 First-Come, First-Served Scheduling
---

매우 간단한 CPU-scheduling 알고리즘은 `first-come, first-served`(`FCFS`) 스케줄링 알고리즘이다. 이 스키마와 함께, CPU를 먼저 요청하는 프로세스에 먼저 CPU가 할당된다. FCFS policy의 구현은 FIFO queue로 쉽게 관리된다. 프로세스가 ready queue에 진입할 때, 프로세스의 PCB는 queue의 꼬리에 연결된다. CPU가 자유로워지면 queue의 머리에 위치한 프로세스에 할당된다. 그러면 실행 중인 프로세스는 queue에서 제거된다. FCFS scheduling을 위한 코드는 작성과 이해가 쉽다.

FCFS policy의 단점으로는 종종 평균시간이 꽤 길다는 것이다. 다음의 시간 0에 도작한 프로세스 집합과 milliseconds로 주어진 CPU burst의 길이를 생각해보자.

	Process		Burst Time
	  P1		    24
	  P2		    3
	  P3		    3

프로세스가 P1, P2, P3의 순서로 도착하고, FCFS 순서로 제공 받았다면, 참여하는 프로세스의 각 시작 시간과 완료 시간을 포함하여, 세세한 과정을 설명하는 막대 차트 `Gantt chart`를 얻을 수 있다.

	P1							P2	P3
	0							24	27	30

P1에 대한 대기 시간은 0, P2는 24, P3은 27이다. 그러므로 평균 대기 시간은 17이다. 하지만 프로세스가 P2, P3, P1 순서로 도착했다면 결과는 다음의 Gantt chart일 것이다.

	P2	P3	P1
	0	3	6							30

이제 평균 대기 시간은 3이다. 이 감소는 상당하다. 그러므로 FCFS policy의 평균 대기 시간은 일반적으로 최소가 아니며, 프로세스의 CPU burst time이 크게 다르다면 평균 시간은 상당히 달라질 수 있다.

추가적으로, 동적인 상황에서 FCFS scheduling의 성능을 생각해보자. 하나의 CPU-bound process와 많은 I/O-bound process를 가지고 있다고 가정하자. 프로세스가 시스템으로 전달될 때, 다음의 시나리오가 발생한다. CPU-bound 프로세스는 CPU를 붙잡을 것이다. 이 시간 동안 다른 프로세스들은 자신의 I/O를 완료하고 ready queue로 이동하며 CPU를 기다린다. 프로세스가 ready queue에서 기다리는 동안, I/O device는 쉬고 있다. 결국에 CPU-bound 프로세스는 자신의 CPU burst를 완료하고 I/O device로 이동한다. 짧은 CPU burst를 가진 모든 I/O-bound 프로세스는 빠르게 실행되며 I/O queue로 되돌아간다. 이 시점에서 CPU는 쉬는 상태에 놓인다. 그러면 CPU-bound 프로세스는 ready queue로 되돌아가고 CPU를 할당받는다. 다시, 모든 I/O 프로세스는 CPU-bound 프로세스가 완료될 때까지 ready queue에서 기다리게 된다. 다른 프로세스들이 하나의 큰 프로세스가 CPU를 놓아주기 기다린다면 `convoy effect`가 존재한다. 이 효과로 CPU와 device의 사용이, 더 짧은 프로세스가 먼저 이용될 때보다 낮아질 수 있다.

또한 FCFS scheduling 알고리즘은 nonpreemptive임을 주목하자. CPU가 프로세스에 할당되면 프로세스는 종료 또는 I/O 요청에 의해 CPU를 놓아줄 때까지 CPU를 가지고 있는다. 그러므로 FCFS 알고리즘은, 각 사용자에게 주기적인 간격으로 CPU을 공유를 제공하는 것이 중요한 time-sharing system에서 골칫거리이다. 하나의 프로세스가 길어진 시간 동안 CPU를 가지고 있게 하는 것은 형편없는 것이 될 것이다.

## 6.3.2 Shortest-Job-First Scheduling
---

CPU scheduling을 위한 다른 방법은 `shortest-job-first`(`SJC`) scheduling 알고리즘이다. 이 알고리즘은 각 프로세스의 next CPU burst의 길이와 관련있다. CPU가 이용 가능할 때, CPU는 가장 작은 next CPU burst를 가지고 있는 프로세스에 할당된다. 두 프로세스의 next CPU burst가 서로 같다면 FCFS scheduling 알고리즘은 이것을 깨뜨린다. 스케줄링은 프로세스의 CPU burst의 전체 길이가 아닌 하나의 next CPU burst에 의존하기 때문에, 이 스케줄링에 대한 더 적절한 용어는 *shortest-next-CPU-burst* 알고리즘이 될 수 있다. 대부분의 사람들과 책들이 이 스케줄링 타입을 참고하기 위해서 SJF라는 용어를 사용하기 때문에 여기에서도 SJF를 사용한다.

SJF 스케줄링의 한 예로써, 다음의 프로세스 집합과 milliseconds로 주어진 CPU burst의 길이를 생각하자.

	Process		Burst Time
	   P1		     6
	   P2		     8
	   P3		     7
	   P4		     3

SJF 스케줄링을 사용해서 이 프로세스들을 다음의 Gantt chart처럼 스케줄링 할 것이다.

	P4	P1		P3		P2
	0	3		9		16		24

대기 시간은 P1에 3, P2에 16, P3에 9, P4에 0이다. 그러므로 평균 대기 시간은 7이 된다. FCFS 스케줄링 스키마를 사용한다면 평균 대기 시간은 10.25이다.

SJF 스케줄링은, 주어진 프로세스 집합의 최소 평균 대기 시간을 제공하는 최적의 알고리즘이다. 긴 프로세스 앞으로 짧은 프로세스를 이동하는 것은 긴 프로세스의 대기 시간을 증가시키는 것보다 짧은 프로세스의 대기 시간을 감소시킨다. 결국에는 평균 대기 시간은 감소한다.

SJF 알고리즘의 실제 어려움은 next CPU 요청의 길이를 아는 것이다. batch system에서 long-term job 스케줄링에 대해, 사용자가 작업을 제출할 때 명시한 프로세스 시간 제한을 사용할 수 있다. 이 상황에서 낮은 값은 더 빠른 반응을 의미하지만 너무 낮은 값은 time-limit-exceeded error를 일으키고 사용자에게 다시 제출할 것을 요구하기 때문에, 사용자는 프로세스 시간 제한을 정확하게 측정하여야 한다. SJF 스케줄링은 long-term 스케줄링에서 자주 사용된다.

SJF 알고리즘이 최적이지만 short-term CPU 스케줄링의 레벨에서는 구현될 수 없다. short-term 스케줄링을 사용하면 next CPU burst의 길이를 알 방법이 없다. 이 문제에 대한 한 가지 방법은 approximation SJF 스케줄링을 시도하는 것이다. next CPU burst의 길이를 모르지만 이 값을 예측할 수 있을 것이다. 이 예측은 next CPU burst가 이전의 길이와 유사하리라는 것이다. next CPU burst 길이의 근사값을 계산함으로써 가장 짧으리라 예상된 CPU burst를 가진 프로세스를 선택할 수 있다.

next CPU burst는 일반적으로 이전 CPU burst의 측정된 길이의 `exponential average`로 예측된다. exponential average를 다음의 공식으로 정의할 수 있다.

	수식을 적기가 어려워 공식과 그 설명은 생략
	[p269]

SJF 알고리즘은 preemptive 또는 nonpreemptive가 될 수 있다. 이전 프로세스가 여전히 실행 중인 동안, 새로운 프로세스가 ready queue에 도착했을 때 선택이 발생한다. 새롭게 시작된 프로세스의 next CPU burst는 현재 실행 중인 프로세스의 남은 부분보다 더 짧을 것이다. preemptive SJF 알고리즘은 현재 실행 중인 프로세스를 선점할 것이고, nonpreemptive SJF 알고리즘은 현재 실행중인 프로세스에게 CPU burst를 마칠 수 있도록 할 것이다. preemptive SJF scheduling은 때때로 `shortest-remaining-time-first` scheduling이라고 불린다.

한 예로써, 다음 milliseconds로 CPU burst 길이를 가진 네 개의 프로세스를 생각해보자.

	Process		Arrival Time	Burst Time
	  P1			0				8
	  P2			1				4
	  P3			2				9
	  P4			3				5

프로세스가 위에 나타난 시간에 ready queue에 도착하고 해당 burst time을 필요로 한다면 결과적인 preemptive SJF scheduling은 다음 Gantt chart와 같다.

	P1	P2		P4			P1				P3					
	0	1		5			10				17						26

queue에 오직 하나의 프로세스 P1만 있기 때문에, 시간 0일 때 프로세스 P1가 시작된다. 프로세스 P2는 시간 1에 도착한다. P1을 기다리는 7의 시간은 P2가 요구하는 시간보다 크다. 따라서 프로세스 P1은 선점되고 프로세스 P2가 스케줄링 된다. 이 예의 평균 대기 시간은 [(10-1) + (1-1) + (17-2) + (5-3)]/4 = 26/4 = 6.5이다. nonpreemptive SJF scheduling의 평균 대기 시간은 7.75이다.

## 6.3.3 Priority Scheduling
---

SJF 알고리즘은 일반적인 `priority-scheduling` 알고리즘의 특별한 경우이다. 우선순위는 각 프로세스에 관련있고, CPU는 가장 높은 우선 순위의 프로세스에 할당된다. 같은 우선 순위 프로세스는 FCFS의 순서로 스케줄링 된다. SJF 알고리즘은 단순히 우선 순위 알고리즘이다. 여기에서 우선 순위 (*p*)는 예측된 next CPU burst의 역수이다. CPU burst가 크면 우선 순위는 낮아지고, 또는 그 반대이다.

**높은** 우선 순위와 **낮은** 우선 순위로 스케줄링을 논의함을 주목하자. 우선 순위는 일반적으로 0 - 7, 0 - 4095처럼 고정된 숫자의 범위로 나타난다. 하지만 0이 가장 높은 우선 순위인지, 가장 낮은 우선 순위인지에 대한 일반적인 약속은 존재하지 않는다. 어떤 시스템은 낮은 숫자를 낮은 우선 순위로 사용하고 다른 시스템들은 낮은 숫자를 높은 수선 순위로 사용한다. 이 차이점은 혼동을 일으킬 수 있다. 여기에서는 낮은 숫자를 높은 우선 순위로 나타낸다.

한 예로써, 시간 0에 P1, P2, ..., P5 순서로 도착한, milliseconds CPU burst 길이를 가진 프로세스 집합을 생각해보자.

	Process		Burst Time		Priority
	   P1		    10			    3
	   P2		    1			    1
	   P3		    2			    4
	   P4		    1			    5
	   P5		    5			    2

우선 순위 스케줄링을 사용하면 이 프로세스들을 다음의 Gantt chart로 스케줄링 할 수 있을 것이다.

	P2	P5			P1					P3		P4
	0	1			6					16		18	19

평균 대기 시간은 8.2이다.

우선순위는 내부적으로 또는 외부적으로 정의될 수 있다. 내부적으로 정의된 프로세스는, 프로세스의 우선 순위를 계산하기 위해 측정 가능한 크기를 사용한다. 예를 들어, 시간 제한, 메모리 요구, 열린 파일의 숫자 그리고 평균 CPU burst에 대한 평균 I/O burst의 비율들은 우선 순위 계산에 사용됐다. 외부적인 우선 순위는 프로세스의 중요도, 컴퓨터 사용에 지불 되는 댓가의 종류와 크기, 작업을 지원하는 부서, 정치 등의 os 외부 기준에 의해 설정된다.

우선 순위 스케줄링은 preemptive 또는 nonpreemptive가 될 수 있다. 프로세스가 ready queue에 도착할 때, 프로세스의 우선순위는 현재 실행 중인 프로세스의 우선 순위와 비교된다. preemptive 우선 순위 알고리즘은 새롭게 도착한 프로세스의 우선 순위가 현재 실행 중인 프로세스의 우선 순위보다 높다면 이를 선점할 것이다. nonpreemptive 우선 순위 스케줄링 알고리즘은 단순히 새로운 프로세스를 ready queue의 헤드에 넣어줄 것이다.

우선 순위 알고리즘의 주된 문제는 `indefinite blocking` 또는 `starvation`이다. 실행을 위해 CPU를 기다리고 있는 프로세스는 차단된 것으로 간주될 수 있다. 우선 순위 스케줄링 알고리즘은 무기한으로 기다리고 있는 낮은 우선 순위 프로세스를 남기고 떠날 수 있다. 과하게 로드된 컴퓨터 시스템에서, 높은 우선 순위 프로세스의 꾸준한 스트림은 낮은 우선 순위 프로세스가 CPU를 얻는 것을 차단할 수 있다. 일반적으로, 결국 프로세스가 실행되거나, 컴퓨터 시스템이 충돌을 일으키고 완료되지 않은 모든 낮은 순위 프로세스를 잃어버리는 것이 발생할 것이다.

낮은 우선 순위 프로세스가 무기한으로 차단되는 이 문제의 해결책은 `aging`이다. 에이징은 시스템에서 긴 시간 기다리는 프로세스의 우선순위를 점차적으로 증가 시킨다. 예를 들어 우선 순위의 범위가 127(low) - 0(high)라면, 우선 순위를 10분마다 1씩 증가시킬 수 있다. 결국에는 초기 우선 순위가 127인 프로세스도 시스템 내에서 높은 우선 순위를 가지게 되고 실행될 것이다. 127 우선 순위 프로세스가 0으로 변하기 까지는 32시간이 걸리지 않는다.

## 6.3.4 Round-Robin Scheduling
---

`round-robin` (`RR`) 스케줄링 알고리즘은 특히 time-sharing system을 위해 설계되었다. FCFS 스케줄링과 유사하지만, 시스템이 프로세스 간 스위치할 수 있도록 preemption이 추가된다. `time quantum` 또는 `time slice`라고 불리는 시간의 작은 단위가 정의된다. time quantum은 일반적으로 10 - 100 milliseconds 길이를 갖는다. ready queue는 circular queue로 다룬다. CPU 스케줄러는 ready queue를 오가며, 최대 1 time quantum 간격으로 각 프로세스에 CPU를 할당한다.

RR scheduling을 구현하기 위해서 다시 프로세스의 FIFO queue로써 ready queue를 다루어야 한다. 새로운 프로세스는 ready queue의 꼬리에 추가된다. CPU 스케줄러는 ready queue로부터 첫 번째 프로세스를 선택하고, 1 time quantum 후에 인터럽트 타이머를 설정한다. 그리고 프로세스를 처리한다.

그러면 다음의 두 가지 상황 중 하나가 발생할 것이다. 프로세스가 1 time quantum보다 작은 CPU burst를 가진다면, 프로세스는 자발적으로 CPU를 내놓는다. 그러면 스케줄러는 ready queue에 있는 다음 프로세스를 진행할 것이다. 현재 실행중인 프로세스의 CPU burst가 1 time quantum보다 길다면, 타이머가 종료되고 os에 인터럽트를 발생시킬 것이다. 그리고 context switch가 실행될 것이며 프로세스는 ready queue에 넣어질 것이다. 그러면 CPU 스케줄러는 ready queue에 있는 다음 프로세스를 선택할 것이다.

RR에서 평균 대기 시간은 종종 길다. 시간 0에 도착하고 milliseconds로 주어진 CPU burst 길이를 가진 다음의 프로세스들을 생각하자.

	Process		Burst Time
	   P1		    24
	   P2		    3
	   P3		    3

4 time quantum을 사용한다면 프로세스 P1은 4 milliseconds를 갖는다. 20 milliseconds가 더 필요하기 때문에, 첫 번째 time quantum이 지나면 선점당한다. 그리고 CPU는 큐에 있는 다음 프로세스 P2에 할당된다. 프로세스 P2는 4 milliseconds가 필요하지 않기 때문에 time quantum이 만료되기 전에 종료된다. CPU는 다음 프로세스 P3에 할당된다. 각 프로세스가 1 time quantum씩 받게 되면, CPU는 추가적인 time quantum을 위해 프로세스 P1로 되돌아온다. RR scheduling의 결과는 다음과 같다.

	P1	P2	P3	P1	P1	P1	P1	P1
	0	4	7	10	14	18	22	26	30

이 스케줄링에 대한 평균 대기 시간을 계산해보자. P1은 6(10-4)을 기다리고, P2는 4, P3은 7을 기다린다. 그러므로 평균 대기 시간은 17/3 = 5.66이다.

RR scheduling 알고리즘에서 1 time quantum보다 많은 시간 동안 CPU를 할당받는 프로세스는 없다. 프로세스의 CPU burst가 1 time quantum을 초과한다면 프로세스는 선점당하고 ready queue의 뒤에 넣어진다. 그러므로 RR scheduling 알고리즘은 preemptive이다.

*n* 개의 프로세스가 ready queue에 있고, time quantum이 *q*라면, 각 프로세스는 최대 q time unit으로 CPU 시간의 1/n을 얻는다. 다음 time quantum까지 각 프로세스는 (n-1) x *q* time unit 보다 오래 기다리면 안된다. 예를 들어 5개의 프로세스와 20 milliseconds time quantum이 주어진다면, 각 프로세스는 100 milliseconds 마다 최대 20 milliseconds를 가질 것이다.

RR 알고리즘의 성능은 time quantum에 크게 의존한다. 극단적으로, time quantum이 과하게 크다면 RR policy는 FCFS policy와 같다. 대조적으로 time quantum이 너무 작다면, RR 방식은 많은 수의 context switch를 초래한다. 예를 들어, 10 time unit을 가진 한 개의 프로세스를 가지고 있다고 가정하자. quantum이 12 time unit이라면 프로세스는 오버헤드 없이 1 time quantum 이전에 작업을 마친다. 하지만 quantum이 6 time unit이라면 프로세스는 2 quanta가 필요하고 한 번의 context switch를 초래한다. time quantum이 1 time unit이라면 아홉 번의 context switch가 발생하고 이에 따라서 프로세스의 실행을 느리게 한다.[Figure 6.4, p273]

그러므로 우리는 context-switch time에 대해 time quantum을 크게하고 싶다. context-switch time이 time quantum의 약 10 퍼센트라면, CPU 시간의 10 퍼센트는 context switch에 사용될 것이다. 실제로, 대부분의 현대 시스템은 10 - 100 milliseconds의 time quanta를 가지고 있다. context switch를 위해 요구되는 시간은 일반적으로 10 milliseconds보다 작다. 그러므로 context-switch time은 time quantum의 작은 파편이다.

또한 turnaround time은 time quantum의 크기에 의존한다. [Figure 6.5, p274]에서 볼 수 있듯이, 프로세스 집합의 평균 turnaround time은 time-quantum 크기가 증가함에 따라 반드시 향상되는 것은 아니다. 일반적으로 평균 turnaround time은, single time quantum에서 대부분의 프로세스가 그들의 next CPU burst를 마치면 향상된다. 예를 들어 10 time unit인 세 개의 프로세스와, 1 time unit의 한 quantum이 주어졌다면 평균 turnaround time은 29이다. 하지만 time quantum이 10이라면 평균 turnaround time은 20으로 내려간다. context-switch time이 추가된다면 평균 turnaround time은 더 작은 time quantum에 대해 훨씬 증가한다. 이는 더 많은 context switch가 필요하기 때문이다.

비록 context-switch time과 비교해서 time quantum이 커야하지만 너무 크면 안된다. 일찍이 지적했듯이 time quantum이 너무 크면 RR 스케줄링은 FCFS policy로 약화된다. 경험에 근거한 규칙은 CPU burst의 80퍼센트가 time quantum보다 짧아져야 한다는 것이다.

## 6.3.5 Multilevel Queue Scheduling
---

스케줄링 알고리즘의 다른 구분은 프로세스가 다른 그룹으로 쉽게 구분되는 상황을 위해서 만들어졌다. 예를 들어, 공약수는 `foreground` (interactive) 프로세스와 `background` (batch) 프로세스 사이에서 만들어진다. 이 프로세스의 두 타입은 다른 response-time requirement를 갖고, 그래서 다른 스케줄링이 필요하다. 추가적으로, foreground 프로세스는 background 프로세스보다 높은 (외부에서 정의 된) 우선 순위를 가질 것이다.

`multilevel queue` 스케줄링 알고리즘은 ready queue를 몇 개의 큐로 분할 한다[Figure 6.6, p275]. 프로세스들은 일반적으로 메모리 크기, 프로세스 우선 순위 또는 프로세스 타입과 같은 프로세스의 프로퍼티에 기반하는 하나의 큐에 영구적으로 할당된다. 각 큐는 자신만의 스케줄링 알고리즘을 갖는다. 예를 들어, 분리된 큐는 foreground와 background 프로세스를 위해서 사용될 것이다. foreground 큐는 RR 알고리즘에 의해서 스케줄링 될 것이고, background 큐는 FCFS 알고리즘에 의해서 스케줄링 될 것이다.

여기에 큐 간 스케줄링이 있어야 하는데, 이것은 일반적으로 fixed-priority preemptive scheduling으로서 구현된다. 예를 들어 foreground 큐는 background 큐보다 큰 absolute priority를 가질 것이다.

다섯 개의 큐와 함께 multilevel queue scheduling algorithm의 예를 보자. 큐는 우선 순위는 다음의 순서로 되어 있다.
1. System processes
2. Interactive processes
3. Interactive editing processes
4. Batch processes
5. Student processes

각 큐는 작은 우선 순위 큐보다 큰 absolute priority를 갖는다. 예를 들어 batch queue에 있는 프로세스는, system processes, interactive processes, interactive editing processes에 대한 큐가 모두 비어있지 않다면 실행될 수 없다. batch process가 실행 중인 동안 interactive editing process가 ready queue에 진입했다면 batch process는 선점당한다.

다른 가능성은 큐 간의 time-slice이다. 각 큐는 CPU의 특정 부분을 갖는다. 그러면 큐는 다양한 프로세스 간 스케줄링을 할 수 있다. 예를 들어, foreground-background 큐에서 foreground queue는 자신의 프로세스 간 RR 스케줄링을 위해 CPU time의 80%를 받을 수 있다. 반면 background 큐는, 자신의 FCFS 기반 프로세스에 주기 위해 CPU time의 20%를 받는다.
