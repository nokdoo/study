# 6.6 Real-Time CPU Scheduling
---

실시간 os에 대한 CPU scheduling은 특별한 이슈를 갖는다. 일반적으로 soft real-time system과 hard real-time system을 구분한다. `soft real-time system`은 critical real-time process가 언제 스케줄링 될지에 대한 보증을 제공하지 않는다. 오직 critical 프로세스가 noncritical 프로세스보다 선호될 것만을 보증한다. `hard real-time system`은 더 엄격한 requirement를 갖는다. 한 태스크는 데드라인까지 서비스 되어야 한다. 데드라인을 넘기면 서비스가 전혀 없는 것과 같다. 이번 절에서는 soft, hard real-time os에서 프로세스 스케줄링과 관련된 이슈를 살펴본다.

## 6.6.1 Minimizing Latency
---

real-time system의 event-driven 성질을 생각하자. 일반적으로 이 시스템은 이벤트가 발생하기를 실시간으로 기다린다. 이벤트는 시간 만료와 같은 소프트웨어적, 방해물에 접근하고 있는 자동차가 원격으로 조작되는 것과 같은 하드웨어적 상황에서 발생한다. 이벤트가 발생하면 시스템은 반응하고 가능한 빨리 서비스 하여야 한다. 이벤트가 발생하고부터 서비스될 때까지의 시간의 흐름을 `event latency`라 한다. [Figure 6.12, p284]

일반적으로 이벤트들은 다른 latency requirement를 갖는다. 예를 들어 antilock brake system의 latency requirement는 3 ~ 5 milliseconds일 것이다. 즉 antilock brake를 제어하는 시스템은 바퀴가 미끄러지는 시간부터 이 상황에 반응하고 제어하기 위해 3 ~ 5 milliseconds의 시간을 갖는다. 반응시간이 길어진다면 자동차의 제어불능 상태를 초래한다. 대조적으로 여객기의 레이더를 제어하는 임베디드 시스템은 수 초의 latency period를 용인할 것이다.

다음의 두 레이턴시 타입은 실시간 시스템의 성능에 영향을 준다.
1. Interrupt latency
2. Dispatch latency

`Interrupt latency`는 CPU에 인터럽트가 도착한 시간부터 인터럽트를 서비스하는 루틴의 시작까지를 나타낸다. os는 인터럽트가 발생하면 우선적으로 실행 중인 instruction을 완료하고 발생한 인터럽트의 타입을 결정한다. 그리고 특정 interrupt service routine(ISR)을 사용하는 인터럽트를 서비스하기 전에 현재 프로세스의 상태를 저장해야 한다. 이 태스크를 수행하는데 걸리는 전체 시간이 interrupt latency이다([Figure 6.13, p284]). 명백히, 실시간 os에서는, 실시간 태스크가 즉시 주목 받는 것을 보장하기 위해 인터럽트 레이턴시를 최소화 하는 것이 중요하다. 실제로는, hard real-time system에서 인터럽트 레이턴시는 단순하게 최소화 되어서는 안되고 시스템의 엄격한 requirement를 충족해야 한다.

인터럽트 레이턴시에 기여하는 한 가지 중요한 요소는 인터럽트가 kernel data structure가 업데이트 되는 동안 비활성화되는 시간의 총 합이다. 실시간 os는 매우 짧은 시간만 인터럽트가 비활성화 되기를 요구한다.

프로세스를 중단하고 다른 프로세스를 시작하는 scheduling dispatcher에 요구된 총 시간은 dispatch latency로 알려져있다. CPU에 즉시 접근하는 실시간 태크스를 제공하는 것은 실시간 os가 dispatcher latency를 최소화하게 한다. 낮은 dispatch latency를 유지하는 가장 효율적인 기술은 preemptive kernel을 제공하는 것이다.

[Figure 6.14, p285]에 dispatch latency의 구조를 그렸다. dispatcher latency의 `conflict phase`는 다음 두 개의 컴포넌트를 갖는다.
1. 커널에서 실행 중인 프로세스의 선점
2. 낮은 우선순위 프로세스에 의한 release. (이 프로세스는 높은 우선순위 프로세스가 필요로하는 자원의 프로세스이다.)

예로써, Solaris에서 preemption이 비활성화된 dispatch latency는 100 milliseconds를 넘는다. preemption이 활성화되면 1 milliseconds 미만으로 줄어든다.

## 6.6.2 Priority-Based Scheduling
---

실시간 os의 가장 중요한 특징은, 프로세스가 CPU를 요구하자마자 실시간 프로세스에 반응하는 것이다. 결과적으로 실시간 os에 대한 스케줄러는 우선순위에 기반한 preemption 알고리즘을 지원해야 한다. 우선순위에 기반한 알고리즘은 각 프로세스 중요도에 따른 우선순위를 할당하는 것을 기억하자. 더 중요한 태스크가 높은 우선순위를 갖는다. 스케줄러가 preemption을 지원한다면, CPU에서 현재 실행 중인 프로세스는 더 높은 우선순위 프로세스가 실행가능해지면 선점당할 것이다.

preemptive이고 우선순위에 기반하는 알고리즘은 6.3.3 절에서 자세히 설명했다. 6.7절은 Linux, Windows, Solaris os의 soft real-time scheduling의 예를 보여준다. 이 시스템들 각각은 가장 높은 스케줄링 우선순위를 실시간 프로세스에 할당한다. 예를 들어, Windows는 32 등급의 우선순위를 가지고 있는데 가장 높은 우선순위 값 16-31은 실시간 프로세스를 위해 예약되었다. Solaris와 Linux는 비슷한 우선순위 스키마를 갖는다.

preemptive이고 우선순위에 기반하는 스케줄러를 제공하는 것은 soft real-time functionality만을 보장함을 주목하라. hard real-time system은 실시간 태스크가 데드라인 requirement에 따라 서비스되는 것을 추가로 보장해야 하며, 이를 확립하기 위해서 추가적인 스케줄링 특성이 필요하다. 이번 절의 남은 부분에서는 hard real-time system에 대한 적절한 스케줄링 알고리즘을 다룬다.

하지만 스케줄러를 개별적으로 자세히 보기전에 스케줄링 되는 프로세스의 특정 특성을 정의해야 한다. 첫 째로 프로세스는 `periodic`이다. 이것은 정해진 주기로 CPU를 요구한다. 프로세스는 CPU를 얻으면, CPU에 의해 서비스되어야 하는 고정된 processing 시간 *t*와 데드라인 *d* 그리고 주기 *p*를 가진다. processing 시간, 데드라인, 주기의 관계는 0 <= *t* <= *d* <= *p*로 나타낼 수 있다. periodic 태스크의 `rate`는 1/*p*이다. [Figure 6.15, p286]은 시간에 따른 periodic 프로세스의 실행을 설명한다. 스케줄러는 이 특성의 이점을 얻을 수 있고 프로세스의 데드라인 또는 rate requirement에 따른 우선순위를 할당할 수 있다.

이 스케줄링 형태의 특이점은 프로세스가 자신의 데드라인 requirement를 스케줄러에게 알려야 한다는 것이다. 그러면 `admission-control` 알고리즘이라는 기술을 사용하여 스케줄러는 다음의 둘 중 하나를 수행한다. 프로세스가 시간 내에 완료하는 것을 보장하거나, 태스크가 데드라인까지 서비스 될 것을 보장하지 못 한다면 불가능한 것으로 간주하고 요청을 거절한다.

## 6.6.3 Rate-Monotonic Scheduling
---

`rate-monotonic` 스케줄링 알고리즘은 preemption을 가진 static priority policy을 사용하는 periodic 태스크를 스케줄링 한다. 낮은 우선순위 프로세스가 실행 중일 때, 높은 우선순위 프로세스가 실행 가능하게 된다면 이는 낮은 우선순위 프로세스를 선점할 것이다. periodic 태스크는 시스템에 진입하자마자 자신의 주기의 역순으로 우선순위를 할당 받는다. 주기가 짧다면 높은 우선순위를, 주기가 길다면 낮은 우선순위를 갖는다. 이 정책에 숨은 이론적 해석은 CPU를 더 자주 요구하는 태스크에 높은 우선순위를 할당하는 것이다. 추가적으로 rate-monotonic 스케줄링은 periodic 프로세스의 processing 시간이 각 CPU burst과 같다고 가정한다. 즉, 프로세스가 CPU를 얻을 때마다 CPU burst의 지속시간은 같다.

한 예를 생각하자. 두 개의 프로세스 *P1*, *P2*가 있다. 각각의 주기는 50과 100이고 *p1*, *p2*로 나타낸다. processing time은 *P1*에 대해서 *t1* = 20이고 *P2*에 대해서 *t2* = 35이다. 각 프로세스에 대한 데드라인은 다음 주기가 시작할 때까지 자신의 CPU burst를 완료하기를 요구한다.

우선 우리는 이 태스크를 각자의 데드라인을 지키게 스케줄링하는 것이 가능한지를 질문해야 한다. 프로세스 *Pi*의 CPU 사용을 주기에 대한 burst의 비율, *ti*/*pi*로 측정한다면 *P1*의 CPU 사용은 20/50 = 0.40이고 *P2*의 CPU 사용은 35/100 = 0.35 이다. 전체 CPU 이용은 75 퍼센트이다. 그러므로 이것은 우리가 이 태스크들을 데드라인을 지키고 CPU에 이용가능한 cycle을 남기는 방법으로 스케줄링할 수 있는 것처럼 보인다.

*P2*에 *P1*보다 높은 우선순위를 할당한다고 가정하자. [Figure 6.16, p287]는 *P1*, *P2*가 실행되는 상황을 보여준다. 볼 수 있듯이, *P2*는 먼저 실행되어 시간 35에 끝난다. 이 때 *P1*이 시작하게 되고, CPU burst를 시간 55에 완료한다. 하지만 *P1*에 대한 데드라인은 시간 50까지이다. 따라서 스케줄러는 이 데드라인을 놓치는 원인이 된다.

`rate-monotonic` 스케줄러를 사용한다고 가정하자. 이것은 *P1*의 주기가 *P2*보다 짧기 때문에 *P1*에 *P2*보다 높은 우선순위를 할당한다. [Figure 6.17, p287]은 이런 상황에서 프로세스의 실행을 보여준다. 먼저 *P1*이 시작되고 CPU burst를 시간 20에 마치고 이는 첫 번째 데드라인을 지킨다. *P2*는 이 시점에 실행되고 시간 50까지 실행된다. 시간 50에서는, *P2*의 CPU burst에 아직 5만큼의 시간이 남아있지만 *P1*에 의해 선점당한다. *P1*은 시간 70에서 CPU burst를 완료하고 스케줄러는 *P2*를 재개한다. *P2*는 데드라인을 지키며 시간 75에 CPU burst를 완료한다. 이 시스템은 *P1*이 다시 스케줄링 되는 시간 100까지 idle 상태로 있는다.

rate-monotonic 스케줄링은, 프로세스의 집합이 이 알고리즘에 의해 스케줄링 될 수 없다면 static priority를 할당하는 다른 알고리즘에 의해서도 스케줄링 될 수 없기에 최적으로 여겨진다. rate-monotonic 알고리즘을 사용하여 스케줄링 될 수 없는 다음의 프로세스 집합을 보자.

프로세스 *P1*이 주기 *p1* = 50, CPU burst *t1* = 25를 갖는다고 추정하자. *P2*에 대해서는 *p2* = 80, *t2* = 35이다. rate-monotonic 스케줄링은 *P1*가 더 짧은 주기를 가지고 있기 때문에 높은 우선순위를 할당할 것이다. 두 프로세스의 전체 CPU이용은 (25/50) + (35/80) = 0.94이다. 두 프로세스가 스케줄링 되고 여전히 6 퍼센트의 이용 가능한 시간이 남았기에 논리적인 것처럼 보인다. [Figure 6.18, p288]은 프로세스 *P1*, *P2*의 스케줄링을 보여준다. 초기에는 *P1*이 CPU burst를 완료하는 시간 25까지 실행된다. 그리고 프로세스 *P2*가 시작되어 시간 50까지 실행된다. 시간 50에서는 *P1*에 의해 선점되고 *P2*는 아직 시간 10만큼의 CPU burst가 남아있다. *P1*이 시간 75까지 실행되고 결국에는 *P2* CPU burst를 완료하기 위한 데드라인, 시간 80을 놓치게 된다.

최적임에도 불구하고 rate-monotonic 스케줄링은, CPU 사용이 묶여 있고 항상 CPU의 자원을 극대화 하는 것이 가능하지는 않다는 한계를 가지고 있다. *N*개의 프로세스를 스케줄링하기 위한 최악의 CPU 사용은 
	
*N*(2^(1/*N*) - 1)

이다. 시스템에 하나의 프로세스를 가지면 CPU의 사용은 100 퍼센트이다. 하지만 프로세스의 수가 무한에 근접한다면 약 69 퍼센트로 떨어진다. 두개의 프로세스를 가지면 CPU의 사용은 약 83 퍼센트이다. [Figure 6.16, p287]과 [Figure 6.17, p287]에서 스케줄링 된 두 프로세스를 위한 CPU의 사용은 75 퍼센드다. 그러므로 rate-monotonic 스케줄링 알고리즘은 이들이 데드라인을 지키기 위해 스케줄링 되는 것을 보장 받는다. [Figure 6.18, p288]에서 스케줄링 된 두 프로세스에 대한 CPU의 사용은 약 94 퍼센트이다. 그러므로 rate-monotonic 스케줄링은 이들이 데드라인을 지키도록 스케줄링 하는 것을 보장할 수 없다.

## 6.6.4 Earliest-Deadline-First Scheduling
---

`earliest-deadline-first`(`EDF`) 스케줄링은 데드라인에 따른 우선순위를 동적으로 할당한다. 가장 빠른 데드라인은 높은 우선순위를, 가장 늦는 데드라인은 낮은 우선순위를 할당한다. EDF 정책에서 프로세스가 실행 가능해질 때 프로세스는 데드라인 requirement를 시스템에 알려야 한다. 우선순위는 새롭게 실행 가능해진 프로세스의 데드라인을 반영하여 조정되어야 한다. 우선순위가 고정되어 있을 때, rate-monotonic 스케줄링과 어떻게 다른지 주목하자. 

EDF 스케줄링을 설명하기 위해서, rate-monotonic 스케줄링으로 데드라인 requirement를 충족하지 못하는 것을 보여준 [Figure 6.18, p288]의 두 프로세스를 다시 스케줄링 한다. *P1*은 *p1* = 50, *t1* = 25을 *P2*는 *p2* = 80, *t2* = 35를 가지고 있다. 이 프로세스들에 대한 EDF 스케줄링은 [Figure 6.19, p289]에 있다. 프로세스 *P1*은 가장 빠른 데드라인을 가지고 있다. 그래서 초기에 프로세스 *P2*보다 높은 우선순위를 갖는다. 프로세스 *P2*은 *P1*에 대한 CPU burst가 종료되면 실행을 시작한다. rate-monotonic 스케줄링이 다음 주기가 되는 시간 50에서 *P1*이 *P2*를 선점하도록 하는 반면, EDF 스케줄링은 *P2*가 계속 실행되도록 허용한다. *P2*는 *P1*보다 더 이른 데드라인을 가지고 있기 때문에(80<100) 더 높은 우선순위를 갖는다. 그러므로 *P1*, *P2* 모두 첫 데드라인을 지킨다. 프로세스 *P1*은 다시 시간 60에 실행되고 시간 85에 두 번째 CPU burst를 완료한다. 또한 시간 100인 두 번째 데드라인을 지킨다. *P2*은 시간 85에 시작되고 다음 주기의 시작인 시간 100에서 *P1*에 의해서 선점당한다. *P1*이 *P2*보다 이른 데드라인을 가지고 있기 때문에(150<160) *P2*는 선점당한다. 시간 125에서는 *P1*이 CPU burst를 완료하고 *P2*는 실행을 재개하며 시간 145에서 데드라인을 지키며 작업을 마친다. 시스템은 *P1*이 다시 스케줄링 되는 시간 150까지 idle 상태이다.

rate-monotonic 알고리즘과는 다르게, EDF 스케줄링은 프로세스가 주기적일 것을 요구하지 않으며 burst 별 고정된 CPU 시간을 요구하지도 않는다. requirement는 오직 프로세스가 실행 가능할 때 스케줄러에게 데드라인을 알리는 것 뿐이다. EDF 스케줄링의 매력은 이론적으로 최적이라는 것이다. 이것은 각 프로세스가 데드라인 requirement를 지킬 수 있게 하고 CPU 사용이 100 퍼센트가 되도록 스케줄링 할 수 있다. 하지만 실전에서는 프로세스와 인터럽트 핸들 간 context switching 비용 때문에 이런 CPU 사용 레벨을 달성하는 것은 불가능하다.

## 6.6.5 Proportional Share Scheduling
---

`proportional share` 스케줄러는 모든 어플리케이션에 몫 *T*를 할당하여 동작한다. 한 어플리케이션은 시간의 몫 *N*을 받을 수 있고, 전체 processor 시간의 *N*/*T*를 갖게 보장받는다. 한 예로 전체 몫 *T* = 100가 *A*, *B*, *C* 세 프로세스로 분할되었다고 가정하자. *A*는 몫 50을 할당받고, *B*는 몫 15, *C*는 몫 20을 할당받는다. 이 스키마는 *A*가 전체 processor 시간의 50 퍼센트를 *B*는 15 퍼센트, *C*는 20퍼센트를 갖게 한다.

proportional share 스케줄러는 한 어플리케이션이 시간의 몫을 할당받는 것을 보장하기 위해 admission-control policy와 함께 동작한다. admission-control policy는, 충분한 몫이 있을 때만 사용자가 특정 수의 몫을 요청하는 것을 허용할 것이다. 위의 예에서는 몫 100 중 50+15+20 = 85 몫을 할당했다. 새로운 프로세스 *D*가 몫 30을 요청했다면 admission controller는 *D*가 시스템에 진입하는 것을 차단할 것이다.

## 6.6.6 POSIX Real-Time Scheduling
---

POSIX 표준은 POSIX.1b와 같은 실시간 컴퓨팅에 대한 확장을 제공한다. 여기에서 실시간 스레드를 스케줄링하는 것과 관련된 POSIX API의 일부를 다룬다. POSIX는 실시간 스레드를 위한 두 스케줄링 클래스를 정의한다

* *SCHED_FIFO*
* *SCHED_RR*

*SCHED_FIFO*는 6.3.1절에서 보여진, FIFO 큐를 사용하는 first-come, first-served policy에 따라 스레드를 스케줄링 한다. 하지만 같은 우선순위 스레드 간 time slicing이 없다. 그러므로 FIFO 큐의 맨 앞에 있는, 가장 높은 우선순위 실시간 스레드는 종료되거나 차단될 때까지 CPU를 부여받을 것이다. *SCHED_RR*은 round-robin policy를 사용한다. 이는 같은 우선순위 스레드 간 time slicing이 있는 것을 제외하면 *SCHED_FIFO*와 유사하다. POSIX는 추가적인 스케줄링 클래스 *SCHED_OTHER*을 제공하지만, 구현이 정의되어 있지 않고 시스템에 따라 다르다. 즉 시스템 마다 다르게 행동한다. POSIX API는 스케줄링 정책을 가져오고 설정하기 위해 다음 두 함수를 명시한다.

* *pthread_attr_getsched_policy(pthread_attr_t &#42;attr, int &#42;policy)*
* *pthread_attr_setsched_policy(pthread_attr_t &#42;attr, int policy)*

두 함수의 첫 번째 파라미터는 스레드의 속성 설정에 대한 포인터다. getting 함수의 두 번째 파라미터는 현재 스케줄링 정책에 설정된 정수를 가리키는 포인터고, setting 함수의 두 번째 파라미터는 *SCHED_FIFO*, *SCHED_RR*, *SCHED_OTHER*의 정수값이다. 두 함수는 에러가 발행하면 0이 아닌 값을 반환한다.

[Figure 6.20, p291]은 이 API를 사용하는 POSIX Pthread 프로그램을 설명한다. 이 프로그램은 우선 현재 스케줄링 정책을 결정하고 스케줄링 알고리즘을 *SCHED_FIFO*로 설정한다.

