# 6.8 Algorithm Evaluation
---

특정 시스템을 위한 CPU-scheduling 알고리즘을 어떻게 선택할 것인가? 6.3절에서 보았듯이 많은 스케줄링 알고리즘이 존재하며, 각각은 자체 파라미터를 갖는다. 따라서, 알고리즘을 선택하는 것은 어려워질 수 있다.

알고리즘을 선택하는데 있어 사용되는 표준을 정의하는 것이 첫 번째 문제이다. 6.2절에서 보았듯이 표준은 종종 CPU의 사용, 응답 시간, 또는 전부에 정의되어 있다. 알고리즘을 선택하기 위해서 우선적으로 이 요소의 상대적인 중요도를 정의해야 한다. 우리의 표준은 다음과 같은 몇 가지 기준을 포함한다.

* 최대 응답시간이 1초인 상황에서 CPU 사용을 최대화한다.
* turnaround time과 같은 처리량을 최대화하는 것은 전체 실행 시간에 선형적으로 비례한다.

표준 선택이 정의되면, 우리는 생각한 알고리즘을 평가하고자 한다. 이제 우리가 사용할 수 있는 다양한 평가 방법을 설명한다.

## 6.8.1 Deterministic Modeling
---

평가 방법의 한 major class는 `analytic evaluation`이다. analytic evaluation은 주어진 알고리즘과 system workload을 사용한다. 이들은 해당 workload의 알고리즘 성능을 측정하기 위한 공식과 숫자를 생성한다.

`deterministic modeling`은 analytic evaluation의 한 가지 타입이다. 이 방법은 미리 결정된 workload를 취하고 해당 workload에 대한 각 알고리즘의 성능을 정의한다. 예를 들어, 아래의 workload를 가지고 있다고 생각하자. 다섯 개의 프로세스는 각각 milliseconds 단위의 CPU burst 길이를 가지고 있으며, 순서대로 시간 0에 도착했다.

	Process		Burst Time
	P1			10
	P2			29
	P3			3
	P4			7
	P5			12

이 프로세스 집합에 대한 FCFS, SJF, RR(quantum = 10) 스케줄링 알고리즘을 생각해보자. 어떤 알고지름이 가장 작은 평균 대기 시간을 갖는가?

FCFS 알고리즘은 다음처럼 실행된다.

P1		P2				P3	P4		P5
0		10				39	42		49		61

P1을 기다리는 시간은 0 milliseconds 이며, P2는 10 milliseconds, P3은 39 milliseconds, P4는 42 milliseconds, P5는 49 milliseconds이다. 그러므로 평균 대기 시간은 (0 + 10 + 39 + 42 + 49) / 5 = 28 milliseconds이다.

nonpreemptive SJF 스케줄링은 다음처럼 실행된다.

P3	P4		P1		P5		P2
0	3		10		20		32				61

P1을 기다리는 시간은 10 milliseconds 이며, P2는 32 milliseconds, P3은 0 milliseconds, P4는 3 milliseconds, P5는 20 milliseconds이다. 그러므로 평균 대기 시간은 (10 + 32 + 0 + 3 + 20) / 5 = 13 milliseconds이다.

RR 알고리즘은 다음처럼 실행된다.

P1		P2		P3	P4	P5		P2		P5	P2
0		10		20	23	30		40		50	52		61

P1을 기다리는 시간은 0 milliseconds 이며, P2는 32 milliseconds, P3은 20 milliseconds, P4는 23 milliseconds, P5는 40 milliseconds이다. 그러므로 평균 대기 시간은 (0 + 32 + 20 + 23 + 40) / 5 = 23 milliseconds이다.

여기에서 SJF로 얻는 평균 대기 시간은 FCFS 보다 반 이상 적다. RR 알고리즘은 두 번째로 큰 값을 준다.

deterministic modeling은 간단하고 빠르다. 이것은 우리가 알고리즘을 비교할 수 있는 정확한 시간을 준다. 하지만 이것은 입력을 위한 정확한 숫자를 요구한다. 그리고 오직 해당되는 케이스에만 답을 준다. deterministic modeling의 주된 사용은 스케줄링 알고리즘을 설명하는 것과 예를 제공하는 것에 있다. 우리가 같은 프로그램을 여러 번 반복 실행하여 프로그램의 처리 조건을 정확하게 측정할 수 있는 상황에서, 스케줄링 알고리즘을 선택하기 위해 deterministic modeling을 사용할 수 있을 것이다. 예제를 통해, deterministic modeling은 경향을 나타낼 것이며, 이 경향은 독립적으로 분석되고 증명될 수 있다. 예를 들어 이것은, 기술된 조건에서(시간 0일 때의 모든 프로세스와 각자의 이용 가능한 시간), SJF 정책은 항상 최저 대기 시간을 가져다 줄 것이다.

## 6.8.2 Queueing Models
---

많은 시스템에서, 실행되는 프로로세스는 매일 다르다. 따라서 deterministic modeling을 사용하기 위한 고정된 프로세스(또는 시간)의 집합이 존재하지 않는다. 하지만 CPU burst와 I/O burst의 분포가 결정될 수 있다. 이 분포는 측정될 수 있고, 거의 정확하게 또는 간단하게 추정될 수 있다. 결과는 특정 CPU burst의 비율을 설명하는 수학적 공식이다. 일반적으로 이 분포는 지수적이고 그 평균에 의해 설명된다. 비슷하게 프로세스가 시스템에 도착할 때(도착 시간 분포) 시간의 분포를 설명할 수 있다. 이 두 분포로부터 대부분의 알고리즘에 대한 평균 처리량, 사용, 대기 시간 등을 계산하는 것이 가능하다.

컴퓨터 시스템은 서버의 네트워크로 설명된다. 각 서버는 대기 프로세스의 큐를 가지고 있다. CPU는 ready queue를 가진 서버이고, 자신의 device queue를 가진 I/O 시스템이다. 도착 비율과 서비스 비율을 알면 사용과 평균 길이, 평균 대기 시간 등을 계산할 수 있다. 이 연구 영역은 `queueing-network analysis`라 불린다.

예로써, *n*을 평균 큐 길이라 하고(서비스되고 있는 프로세스를 제외한), *W*를 큐에서의 평균 대기 시간이라고 하자. 그리고 *λ*를 큐에 새롭게 도착하는 큐의 평균 도착 비율이라고 하자(3프로세스 / 1초 와 같은). 프로세스가 기다리는 시간 *W*동안 *λ* x *W*개의 새로운 프로세스가 큐에 도착할 것이다. 시스템이 안정적인 상태라면 큐를 떠나는 프로세스의 수는 도착하는 프로세스의 수와 같아야만 한다. 따라서

	*n* = *λ* x *W*

이다. 이 등식은 `Little's formala`로 알려져 있고 어떠한 스케줄링 알고리즘과 도착 분포에 대해서도 유효하기 때문에 특히 유용하다.

세 가지 변수 중 두 개의 변수를 알고 있다면 남은 하나를 계산하기 위해서 Little's formala를 사용할 수 있다. 예를 들어, 7개의 프로세스가 매 초(평균적으로) 도착하는 것과 큐에는 일반적으로 14개의 프로세스가 있다는 것을 알고 있다면, 프로세스 당 평균 대기 시간을 2초로 계산할 수 있다. 

Queueing analysis는 스케줄링 알고리즘을 비교하는데 유용하지만 제약을 가지고 있다. 지금은 알고리즘의 클래스와 핸들될 수 있는 분포가 상당히 제약된다. 복잡한 알고리즘의 계산과 분포는 함께 작업하기 어려워질 수 있다. 그러므로 도착과 서비스 분포는 종종 수학적으로 다루기 쉬운 방법으로(그러나 비현실적인) 정의된다. 또한 이것은 일반적으로 많은 수의 독립적 가정을 만들 필요가 있고, 정확해지지 않는다. 이 어려움 때문에 queueing model은 종종 실제 시스템의 근사치가 되고, 계산된 결과의 정확도는 의심스러워진다.

## 6.8.3 Simulations
---

스케줄링 알고리즘의 더 정확한 측정을 얻기 위해서 simulation을 사용할 수 있다. simulation을 실행하는 것은 컴퓨터 시스템의 모델을 프로그래밍 하는 것을 포함한다. 소프트웨어 data structure는 시스템의 major 컴포넌트를 나타낸다. simulator는 시간을 나타내는 변수를 갖는다. 이 변수의 값이 증가하기 때문에 simulator는 디바이스, 프로세스, 스케줄러의 활동을 반영하기 위한 시스템 상태를 수정할 수 있다. simulation을 실행할 때 알고리즘의 성능을 나타내는 통계가 얻어지고 출력된다.

simulation을 수행하기 위한 데이터는 몇 가지 방법으로 생성될 수 있다. 가장 일반적인 방법은, 확률 분포를 따르는 프로세스, CPU burst time, arrival departure 등을 생성하기 위해 프로그램된 random-number generator를 사용한다. 이 분포는 수학적으로(uniform, exponential, poisson) 또는 경험적으로 정의될 수 있다. 한 분포가 경험적으로 정의된다면, 연구가 이루어지고 있는 실제 시스템의 측정이 수행된다. 결과는 실제 시스템의 이벤트 분포를 정의한다. 그러면 이 분포는 simulation을 수행하는데 사용될 수 있다.

하지만 실제 시스템에서 연속적인 이벤트 간 관계 때문에 distribution-driven simulation은 부정확할 것이다. 도수 분포는 각 이벤트의 인스턴스가 얼마나 많이 발생하는지만 나타낸다. 이것은 이들의 발생 순선에 대해서 아무것도 나타내지 않는다. 이 문제를 올바르게 만들고자 `trace tapes`를 사용할 수 있다. 실제 시스템을 모니터링하고 실제 이벤트 시퀀스를 기록함으로써 trace tape를 생성할 수 있다([Figure 6.25]). 그러면 우리는 simulation을 수행하기 위한 시퀀스를 사용한다. trace tape는 두 알고리즘을 비교하기 위한 훌륭한 방법을 제공한다. 이 방법은 입력에 대한 정확한 결과를 만들 수 있다.

simulation은 비싸질 수 있고 종종 몇 시간의 컴퓨터 시간을 필요로 할 수 있다. 더 자세한 simulation은 더 정확한 결과를 제공하지만 더 많은 컴퓨터 시간을 필요로 한다. 추가적으로 trace tape는 더 큰 저장 공간을 요구할 수 있다. 최종적으로 simulator의 설계, 코딩, 디버깅이 major 태스크가 될 수 있다.

## 6.8.4 Implementation
---

simulation도 정확성이 제한적이다. 스케줄링 알고리즘을 펼가하기 위한 오직 완벽한 방법은 코드화 하여 os에 넣고 이것이 어떻게 동작하는지 지켜보는 것이다. 이 접근은 real operating condition 상황에서, 평가를 위해 실제 알고리즘을 실제 시스템에 넣는다.

이 접근법의 주된 어려움은 비용이 높다는 것이다. 이 비용은 알고리즘을 코딩하는 것과 이를 지원하기 위해 os를 수정하는 것 말고도, 꾸준히 변화하는 os에 대한 사용자의 반응에서도 발생한다. 대부분의 사용자는 더 좋은 os를 구축하는 것에 관심이 없다. 이들은 단지 실행한 프로세스를 얻고 그 결과를 사용하고 싶을 뿐이다. 꾸준히 변화하는 os는 사용자가 작업이 끝난 작업을 얻도록 돕지 않는다.

다른 어려움은 알고리즘이 사용되고 있는 환경이 바뀐다는 것이다. 환경은 새로운 프로그램이 작성되거나 문제의 타입이 변경되는 것과 같은 일반적인 것 외에 스케줄러의 성능의 결과로도 바뀐다. 짧은 프로세스가 우선 순위를 받았다면 사용자는 더 큰 프로세스를 더 작은 프로세스의 집합으로 쪼갤 수 있다. interactive 프로세스가 noninteractive 프로세스보다 높은 우선 순위를 받는다면 사용자는 interactive 사용으로 전환할 것이다.

예를 들어, 연구자가 터미널 I/O의 총 합을 보면서 interactive와 noninteractive 프로세스를 자동적으로 분류한 시스템을 설계했다. 한 프로세스가 1초 간격으로 터미널에 입력 또는 출력을 하지 않는다면 프로세스는 noninteractive으로 분류되고 낮은 우선 순위 큐로 이동된다. 이 정책에 대한 반응으로 한 프로그래머는 그의 프로그램을 임의의 캐릭터를 1초가 안되는 규칙적인 간격마다 입력하도록 수정했다. 이 시스템은 비록 터미널이 완전히 의미 없는 출력을 하더라도 프로그램에 높은 우선 순위를 주었다.

더 유연한 스케줄링 알고리즘은, 특정 어플리 케이션 또는 어플리 케이션 집합에 대해 조정될 수 있도록, 시스템 관리자 또는 사용자에 의해서 수정될 수 있는 것이다. 예로, high-end 그래픽 어플리케이션을 수행하는 워크스테이션은 웹 서버 또는 파일 서버와 다른 스케줄링 요구를 가질 수 있다. 어떤 os는(UNIX의 특정 버전은) 시스템 관리자가 특정 시스템 설정에 대한 스케줄링 파라미터를 fine-tune하도록 허용한다. 예를 들어 Solaris는 시스템 관리자가 6.7.3절의 스케줄링 클래스 파라미터를 수정할 수 있게 *dispadmin* 커맨드를 지원한다.

다른 접근은 프로세스 또는 스레드의 우선 순위를 수정할 수 있는 API를 사용하는 것이다. Java, POSIX, Windows API는 이런 함수를 제공한다. 이 접근법의 실패는 시스템 또는 어플리케이션을 performance-tuning하는 것은, 더 일반적인 상황에서 아주 종종 향상된 성능을 초래하지 않는다는 것이다.
