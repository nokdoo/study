# 6.7 Operating-System Examples
---

Linux, Windows, Solaris os의 스케줄링 정책을 설명한다. 일반적인 *process scheduling* 용어를 사용한다. 실제로는 Solaris, Windows의 *kernel threads* 스케줄링을, Linux 스케줄러의 태스크 스케줄링을 설명한다. (한번 더 보자)

## 6.7.1 Example: Linux Scheduling
---

리눅스에서의 프로세스 스케줄링은 흥미로운 역사를 갖는다. 2.5버전 이전의 리눅스 커널은 전통적인 UNIX 스케줄링 알고리즘의 변형을 실행했다. 하지만 이 알고리즘은 SMP 시스템을 염두하고 설계되지 않았기 때문에 multiple processor를 가진 시스템을 지원하기에는 적절하지 않았다. 추가적으로, 이것은 실행 가능한 많은 수의 프로세스를 가진 시세틈에서는 낮은 성능을 나타냈다. 2.5 버전의 커널에서 스케줄러는 시스템에 있는 태스크의 숫자와 관계없이, *O(1)*로 알려진 일정한 시간에 실행하는 스케줄링 알고리즘을 포함하기 위해 점검되었다. *O(1)* 스케줄러는 processor affinity와 processor간 로드 밸런싱을 포함하여, SMP 시스템에 대한 추가적인 지원을 제공하였다. 실제로 *O(1)* 스케줄러가 SMP 시스템에서 훌륭한 성능을 제공하지만, 많은 데스크톱 시스템의 일반적인 interactive 프로세스에 대한 응답시간은 좋지 않다. 2.6 버전의 커널을 개발하면서 스케줄러는 다시 개정되었다. 그리고 2.6.23 버전의 커널에서 *Completely Fiar Scheduler*(CFS)가 Linux의 기본 스케줄링 알고리즘이 되었다.

Linux 시스템의 스케줄링은 `scheduling classes`에 기반한다. 각 클래스는 특정 우선순위를 할당 받는다. 다른 스케줄링 클래스를 사용함에 따라 커널은 시스템과 그 프로세스가 요구하는 것에 기반한 다른 스케줄링 알고리즘을 수용할 수 있다. 예를 들면, Linux server에 대한 스케줄링 기준은 Linux를 실행하는 모바일 기기에 대한 것과 다를 수 있다. 다음에 실행할 태스크를 결정하기 위해서 스케줄러는 가장 높은 우선순위 스케줄링 클래스에 속한 가장 높은 우선순위 태스크를 선택한다. 표준 Linux 커널은 두 개의 스케줄링 클래스를 구현한다. 하나는 CFS스케줄링 알고리즘을 사용하는 기본 스케줄링 클래스이고, 다른 하나는 실시간 스케줄링 클래스이다. 여기에서는 각각의 클래스를 논의 한다. 물론 새로운 스케줄링 클래스가 추가될 수 있다.

CFS 스케줄러는 상대적 우선순위 값을 시간 할당량의 길이와 연관시키는 엄격한 규칙을 사용하기보다는, CPU processing time 비율을 각 태스크에 할당한다. 이 비율은 각 태스크에 할당된 `nice value`에 기반하여 계산된다. nice value는 -20 ~ +19 범위를 갖고, 낮은 값은 더 높은 상대적 우선순위를 나타낸다. 낮은 nice value 값을 가진 태스크는 높은 nice value를 가진 태스크보다 높은 CPU processing time 비율을 받는다. 기본 nice value 값은 0이다. (*nice*라는 용어는 태스크의 nice value가 증가하면 상대적 우선순위가 낮아지기 때문에, 시스템에 있는 다른 태스크에게 좋다는 생각으로부터 나왔다.) CFS는 time slice의 discrete value을 사용하지 않는 대신, 모든 실행 가능한 태스크는 적어도 한 번 실행되어야 하는 시간 간격인 `targeted latency`를 식별한다. CPU 시간의 비율은 targeted latency의 값으로부터 할당 받는다. 기본 값과 최소값을 갖는 것 외에도, 시스템에서 활동하는 태스크의 숫자가 특정 문턱을 넘게되면 targeted latency는 증가할 수 있다.

CFS 스케줄러는 직접적으로 우선순위를 할당하지 않는다. per-task 변수 *vruntime*을 사용하는 각 태스크의 `virtual run time`을 유지하면서 얼마나 오래 각 태스크를 실행하는지 기록한다. virtual run time은 태스크의 우선순위에 기반한 decay factor와 관련있다. 낮은 우선순위 태스크는 높은 우선순위 태스크보다 높은 decay 비율을 갖는다. 보통의 우선순위(0의 nice value) 태스크에 대해서 virtual run time은 실제 physical run time과 일치한다. 그러므로 기본 우선순위를 가진 태스크가 200 milliseconds 동안 실행된다면, 이 태스크의 *vruntime*은 200 milliseconds가 될 것이다. 하지만 낮은 우선순위 태스크가 200 milliseconds 동안 실행된다면 *vruntime*은 200 milliseconds보다 길어질 것이다. 비슷하게 높은 우선순위 태스크가 200 milliseconds 동안 실행된다면, 이 태스크의 *vruntime*은 200 milliseconds보다 짧아질 것이다. 다음에 실행되는 태스크를 결정하기 위해서, 스케줄러는 단순히 *vruntime* 값이 가장 작은 태스크를 선택한다. 추가적으로, 실행될 수 있게 되는 높은 우선순위 태스크는 낮은 우선순위 태스크를 선점한다. 

	*CFS PERFORMANCE*
	
	Linux CFS 스케줄러는 다음에 실행될 태스크를 선택하는 효율적인 알고리즘을 제공한다. 각 실행 가능한 태스크는, *vruntime*의 값에 기반하는 값을 가진 balanced binary search tree인 red-black tree에 위치한다. 이 트리는 [Figure, p293]에 나타냈다. 태스크는 실행 가능하게 되면 트리에 추가된다. 트리의 태스크가 실행 불가능 하다면(예를 들어, I/O를 기다리느라 차단된 경우) 트리에서 제거된다. 일반적으로, 적은 processing time을(*vruntime*의 가장 작은 값을) 받은 태스크는 트리의 왼쪽으로 향하고, 많은 processing time을 가진 태스크는 트리의 오른쪽으로 향한다. binary search tree의 프로퍼티에 따라 가장 왼쪽에 있는 노드는 가장 작은 키 값을 갖는다. CFS 스케줄러를 위한 이 키 값은 태스크가 높은 우선순위를 가지고 있다는 것을 의미한다. red-black tree는 균형잡혀있기 때문에 가장 왼쪽의 노드를 발견하는 것은 O(lgN) 연산 수가 필요할 것이다(N은 트리의 노드 숫자이다). 하지만 효율적인 이유로 Linux 스케줄러는 이 값을 *rb_leftmost* 변수에 cache한다. 그러므로 다음에 실행될 태스크를 결정하는 것은 cache된 값을 가져오는 것 뿐이다.

실행 중인 CFS 스케줄러를 보자. 두 개의 태스크가 같은 nice value를 갖는다고 가정하자. 한 태스크는 I/O bound 태스크이고 다른 하나는 CPU-bound 태스크이다. 일반적으로 I/O-bound 태스크는 추가되는 I/O를 위해 차단당하기 전까지 짧은 주기동안만 실행될 것이다. CPU-bound 태스크는 processor에서 실행될 기회가 있다면 언제든지 자신의 주기를 사용할 것이다. 그러므로 *vruntime*의 값은 결국, CPU-bound 태스크 보다는 I/O-bound를 위해 더 작아질 것이다. 이 시점에서, I/O-bound 태스크가 실행될 자격을 얻고(I/O 태스크가 실행될 수 있기를 기다리는 상태가 되고) CPU-bound 태스크가 실행 중이라면 I/O bound 태스크는 CPU-bound 태스크를 선점할 것이다.

또한 Linux는 6.6.6절에서 설명된 POSIX 표준을 사용하는 실시간 스케줄링을 구현한다. *SCHED_FIFO* 또는 *SCHED_RR* real-time policy를 사용하는 스케줄링 된 태스크는 보통의 태스크(non-real time 태스크)보다 높은 우선 순위를 가질 때 실행된다. Linux는 두 개의 분리된 우선순위를 사용한다. 하나는 실시간 태스크를 위한 것이고, 다른 하나는 보통의 태스크를 위한 것이다. 실시칸 태스크는 0 - 99 범위의 static priority를 할당받고, 보통의 태스크(non real-time 태스크)는 100 - 139의 우선순위를 할당 받는다. 이 두 범위는, 낮은 값이 더 높은 상대적 우선순위를 나타내는 global priority scheme에 매핑된다. 보통의 태스크는 각자의 nice value에 기반한 우선순위를 할당 받는다. nice value의 값이 -20이면 우선순위 100에 매핑되고 +19면 139에 매핑된다. 이 스키마는 [Figure 6.21, p294]에 나타냈다.

## 6.7.2 Example: Windows Scheduling
---

Windows는 우선순위 기반의 preemptive 스케줄링 알고리즘을 사용하여 스레드를 스케줄링 한다. Windows 스케줄러는 가장 높은 우선순위 스레드가 항상 실행될 것을 보장한다. 스케줄링을 핸들하는 Windows 커널의 일부를 `dispatcher`라고 부른다. 실행되기 위해 DISPATCHER에 선택된 스레드는 더 높은 우선 순위 스레드에 의세 선점당할 때까지, 실행을 종료할 때까지, 주어진 시간이 끝날 때까지, I/O를 위한 차단 system call을 실행할 때까지 실행될 것이다. 스레드가 실행 중인 동안 더 높은 우선순위 실시간 스레드가 준비 상태로 되면, 실행 중인 스레드는 선점당할 것이다. 이 preemption은, 스레드가 이런 액세스를 필요로 할 때 실시간 스레드에게 CPU에 대한 우선 액세스를 제공한다.

dispatcher는 스레드 실행을 결정하기 위한 32 등급의 우선순위 스키마를 사용한다. 우선순위는 두 개의 클래스로 나뉜다. 하나는 1 - 15의 우선순위를 갖는 스레드를 포함한 `variable class`이고, 다른 하나는 16- 31의 우선순위를 갖는 스레드를 포함한 `real-time class`이다. (메모리 관리를 위해 사용되는 우선순위 0에도 실행 중인 스레드가 존재한다.) dispatcher는 각 스케줄링 우선 순위를 위해 큐를 사용하고, 실행 준비가 된 스레드를 찾을 때까지 큐의 집합의 가장 높은 곳에서 낮은 곳까지 탐색한다. 스레드를 찾지 못한다면 dispatcher는 `idle thread`라고 부르는 특별한 스레드를 실행할 것이다.

Windows 커널과 Windows API의 우선순위 사이에는 관계가 존재한다. Windows API는 프로세스가 속할 수 있는 다음 6개의 우선순위 클래스를 식별한다.

* IDLE_PRIORITY_CLASS
* BELOW_NORMAL_PRIORITY_CLASS
* NORMAL_PRIORITY_CLASS
* ABOVE_NORMAL_PRIORITY_CLASS
* HIGH_PRIORITY_CLASS
* REALTIME_PRIORITY_CLASS

일반적으로 프로세스는 NORMAL_PRIORITY_CLASS의 멤버다. 한 프로세스는, 프로세스의 부모가 IDLE_PRIORITY_CLASS의 멤버가 않는 한, 프로세스가 생성되었을 때 다른 클래스가 명시되지 않는 한 NORMAL_PRIORITY_CLASS클래스에 속한다. 추가적으로 프로세스의 우선순위 클래스는 Windows API의 *SetPriorityClass()*함수로 바뀔 수 있다. REALTIME_PRIORITY_CLASS를 제외한 모든 클래스의 우선순위는 변수이다. 이것은 이 클래스 중 하나에 속한 스레드의 우선순위가 바뀔 수 있다는 것을 의미한다.

주어진 우선순위 클래스 내의 스레드는 상대적인 우선순위를 갖는다. 상대적인 우선순위를 위한 값은 다음을 포함한다.

* IDLE
* LOWEST
* BELOW_NORMAL
* NORMAL
* ABOVE_NORMAL
* HIGHEST
* TIME_CRITICAL

각 스레드의 우선순위는, 스레드가 속한 우선순위 클래스와 클래스 내에서 상대적인 우선순위에 기반한다. 이 관계는 [Figure 6.22, p295]에 나타냈다. 우선순위 클래스의 값은 맨 위쪽 행에 나타냈고, 상대적 우선순위는 맨 왼쪽 열에 나타냈다. 예를 들어, ABOVE_NORMAL_PRIORITY_CLASS에 있는 스레드의 상대적인 우선순위가 NORMAL이라면, 스레드의 우선순위는 10이다.

게다가, 각 스레드는 자신이 속한 클래스에 대한 우선순위 범위의 값을 나타내는 기본 우선순위를 갖는다. 기본적으로, 기본 우선순위는 클래스에 대한 NORMAL relative priority의 값이다. 각 우선순위 클래스에 대한 기본 우선순위는 다음과 같다.

* REALTIME_PRIORITY_CLASS - 24
* HIGH_PRIORITY_CLASS - 13
* ABOVE_NORMAL_PRIORITY_CLASS - 10
* NORMAL_PRIORITY_CLASS - 8
* BELOW_NORMAL_PRIORITY_CLASS - 6
* IDLE_PRIORITY_CLASS - 4

Windows API의 *SetThreadPriority()* 함수가 스레드의 기본 우선순위를 바꾸기 위해서 사용될 수 있지만, 스레드의 초기 우선순위는 일반적으로 스레드가 속한 프로세스의 기본 우선순위이다.

스레드에 주어진 시간이 다 되면 스레드는 인터럽트 된다. 스레드가 variable-priority class에 있다면 이 우선순위는 낮아지지만 절대 기본 우선순위 밑으로는 내려가지 않는다. 우선순위를 내리는 것은 compute-bound 스레드의 CPU 사용을 제한하는 경향이 있다. variable priority thread가 wait operation으로부터 릴리즈될 때, dispatcher는 우선순위를 boost한다. boost의 양은 스레드가 기다리고 있던 것에 의존한다. 예를 들어, disk operation을 기다리고 있는 스레드가 적당한 크기의 우선순위를 얻는 반면 키보드 I/O를 기다리고 있는 스레드는 큰 우선순위를 얻을 것이다. 이 전략은 마우스와 창(UI)을 사용하는 interactive thread에게 좋은 반응 시간을 제공하는 경향이 있다. 또한 이것은 compute-bound 스레드가 백그라운드에서 spare CPU cycle을 사용하기 위해 허용하는 동안 I/O bound 스레드가 I/O device를 바쁘게 유지할 수 있게 한다. 이 전략은 UNIX를 포함한 time-sharing os에서 사용된다. 추가적으로 사용자가 현재 사용 중인 창(UI)는 반응 시간을 향상시키기 위해 우선순위 boost를 받는다.

사용자가 interactive program을 실행 중일 때 시스템은 특히 좋은 성능을 제공할 필요가 있다. 이런 이유로, Windows는 NORMAL_PRIORITY_CLASS의 프로세스를 위한 특별한 스케줄링 규칙을 갖는다. Windows는 스크린에서 현재 선택된 `foreground process`와 선택되지 않은 `background process`들을 구분한다. 프로세스가 foreground로 이동할 때, Windows는 약간의 스케줄링 값(일반적으로 3)을 증가시킨다. 이 증가는 time-sharing preemption이 발생하기 전에, foreground 프로세스가 세 배 더 길게 실행되게 한다.

Windows 7은 어플리케이션이 커널에 독립적으로 스레드를 생성하고 관리하도록 하는 `user-mode scheduling`(`UMS`)를 도입했다. 그러므로 어플리케이션은 Windows 커널 스케줄러의 관여없이 multiple thread를 생성하고 스케줄링할 수 있다. 많은 수의 스레드를 생성하는 어플리케이션에 대해서, user mode에서의 스레드 스케줄링은 kernel mode의 스레드 스케줄링보다 더 많이 효율적이다. 이것은 kernel invention이 필요하지 않기 때문이다.

Windows의 이전 버전은, 별도의 user-mode threads(fibers)가 single kernel thread에 매핑되는 것을 허용하는 `fibers`로 알려진 특징을 제공했다. 하지만 fibers는 실제 사용에는 제한적이다. 모든 fiber는 자신이 실행되고 있는 스레드의 thread environment block(TEB)을 공유해야 하기 때문에, fiber는 Windows API를 호출할 수 없다. 이것은 Windows API 함수가 상태 정보를 fiber에 대한 TEB에 두었다면, 다른 fiber에 의해 덮어씌워진 정보를 가지고 있었을 문제를 갖는다. (////) UMS는 각 user-mode 스레드를 자신의 thread context에 제공함으로써 이 문제를 극복한다.

추가적으로 fiber와는 다르게 UMS는 프로그래머로부터 직접 사용되지 않게 의도되었다. user-mode 스케줄러 작성에 대한 자세한 내용은 매우 도전적이다. 그리고 UMS는 스케줄러와 같은 것을 포함하지 않는다. 스케줄러는 UMS의 상단에 빌드된 프로그래밍 언어 라이브러리에 있다. 예를 들어, Microsoft는 `concurrency runtime`(ConcRT)와, multicore processor에서 태스크 기반의 병렬성(4.2절)을 위해 설계된 C++을 위한 병행 프로그래밍 프레임워크를 지원한다. ConcRT는 user-mode 스케줄러를, 프로그램을 태스크로 분해하는 기능과 함께 제공한다. 태스크는 이용 가능한 processing core에서 스케줄링 될 수 있다. UMS에 대한 자세한 내용은 19.7.3.7절에서 확인할 수 있다.

## 6.7.3 Example: Solaris Scheduling
---

Solaris는 우선순위 기반의 스레드 스케줄링을 사용한다. 각 스레드는 다음 여섯 클래스 중 하나에 속한다.

1. Time sharing (TS)
2. Interactive (IA)
3. Real time (RT)
4. System (SYS)
5. Fiar share (FSS)
6. Fixed priority (FP)

각 클래스 안에는 다른 우선순위와 다른 스케줄링 알고리즘이 들어있다.

프로세스에 대한 기본 스케줄링 클래스는 time sharing이다. time-sharing 클래스에 대한 스케줄링 정책은 동적으로 우선선위를 변경하고, multilevel feedback queue를 사용하여 다른 길이의 time slice를 할당한다. 기본적으로 우선순위와 time slice는 반비례 관계이다. 높은 우선순위는 작은 time slice를 할당하고, 낮은 우선순위는 큰 time slice를 할당한다. interactive process는 일반적으로 더 높은 우선순위를 갖는다. CPU-bound 프로세스는 더 낮은 우선순위를 갖는다. 이 스케줄링 정책은 interactive process에 좋은 응답 시간을, CPU-bound 프로세스에 대한 좋은 throughput을 제공한다. interactive 클래스는 time-sharing 클래스와 같은 스케줄링 정책을 사용하지만, KDE나 GNOME 창(UI) 관리자에 의해 생성된 어플리케이션에 더 좋은 성능을 위해서 더 높은 우선순위를 준다.

[Figure 6.23, p298]은 time-sharing, interactive 스레드를 스케줄링하기 위한 dispatch table을 보여준다. 이 두 스케줄링 클래스는 60 등급의 우선순위를 포함하지만, 간결성을 위해 조금만 보여준다. [Figure 6.23, p298]의 dispatch table은 다음의 필드를 포함한다.

* priority - time-sharing, interactive 클래스를 위한 class-dependent priority. 높은 숫자는 높은 우선순위를 나타낸다.
* time quantum - 관련있는 우선순위에 대한 시간의 양. 이것은 우선순위와 시간의 양의 반 비례관계를 설명한다. 가장 낮은 우선순위(0)는 가장 높은 시간의 양(200 milliseconds)을 갖는다. 그리고 가장 높은 우선순위(59)는 가장 낮은 시간의 양을 갖는다(20 milliseconds).
* time quantum expired - 차단 없이 자신의 모든 시간의 양을 사용한 스레드의 새로운 우선순위. 이런 스레드는 CPU-intensive로 간주된다. 테이블처럼 이 스레드는 낮아진 우선순위를 갖는다.
* return from sleep - sleeping(I/O를 기다리는 것과 같은)으로부터 되돌아온 스레드의 우선순위. 테이블에서 설명하듯이 I/O가 스레드를 기다리는 동안 이용가능 할 때, 이 우선순위는 50에서 59로 boost되고 interactive process에 좋은 응답시간을 제공하는 스케줄링 정책을 지원한다.

real-time class에서 스레드는 가장 높은 우선순위를 받는다. 실시간 프로세스는 다른 클래스의 프로세스보다 먼저 실행될 것이다. 이 우선순위 할당은 실시간 프로세스가 한정된 시간 내에 시스템으로부터 보장된 응답을 가지는 것을 허용한다. 하지만 일반적으로 적은 프로세스가 실시간 프로세스에 속한다.

Solaris는 스케줄러, paging daemon과 같은 커널 스레드를 실행하기 위해서 시스템 클래스를 사용한다. 시스템 스레드의 우선순위가 성립되면, 변경되지 않는다. 시스템 클래스는 커널 사용(kernel mode에서 실행 중인 사용자 프로세스는 시스템 클래스에 있지 않다)을 위해 예약되었다.

fixed-priority 클래스와 fair-share 클래스는 Solaris 9에 도입되었다. fixed-priority 클래스의 스레드는 time-sharing 클래스와 같은 우선순위 범위를 갖는다. 하지만 이들의 우선순위는 동적으로 조정되지 않는다. fair-share 스케줄링 클래스는 스케줄링을 결정하기 위해서 우선순위 대신 CPU `몫`을 사용한다. CPU 몫은 이용 가능한 CPU에 자원에 대한 자격을 나타내고, 프로세스의 집합(`project`)에 할당된다.

각 스케줄링 클래스는 우선순위 집합을 포함한다. 하지만 스케줄러는 class-specific 우선순위를 global priority로 전환하고 실행을 위해서 가장 높은 global priority를 가진 스레드를 선택한다. 선택된 스레드는 (1) 차단되거나, (2) time slice를 모두 사용하거나, (3) 더 높은 우선순위 스레드에 의해 선점당할 때까지 CPU에서 실행된다. 같은 우선순위를 가진 multiple thread가 있다면, 스케줄러는 round-robin 큐를 사용한다. [Figure 6.24, p299]는 여섯 개의 스케줄링 클래스가 어떻게 다른 것들과 관련이 있는지, global priority와 어떻게 매핑되는지를 보여준다. kernel이 인터럽트를 서비스하기 위해 10개의 스레드를 관리하는 것을 생각하자. 이 스레드는 어떠한 스케줄링 클래스에 속하지 않고 가장 높은 우선순위(160-169)에서 실행된다. 언급했듯이, Solaris는 전통적으로 many-to-many mmodel(4.3.3절)을 사용했지만, Solaris 9의 시작과 함께 one-to-one model(4.3.2절)로 전환하였다.

