# 5.6 Semaphores
---

말했듯이 mutex lock은 synchronization tool의 가장 간단한 것으로 간주된다. 이번 절에서는 mutex lock만큼 간단하면서도, 프로세스 활동의 synchronize를 위한 정교한 방법을 제공하는 툴을 다룬다.

`semaphore` S 는 초기화로부터 분리된 변수이며 오직 standard atomic operation *wait()*, *signal()*에 의해서만 접근되는 정수 변수이다. *wait()* operation은 P라고 불린다.(테스트의 네덜란드어 ***proberen***) *signal()* operation은 V라고 불린다.(증가라는 말의 ***verhogen***) *wait()*의 정의는 다음과 같다.

	wait(S){
		while(S <= 0)
			; // busy wait
		S--;
	}

*signal()*의 정의는 다음과 같다.

	signal(S){
		S++;
	}

*wait()*, *signal()* operation의 세마포어 정수 값을 수정하는 것은 항상 같이 실행된다. 즉, 한 프로세스가 세마포어 값을 수정할 때 다른 프로세스는 같은 세마포어 값을 동시에 수정할 수 없다. 여기에 *S*의 값을 확인하고, 값을 감소시키는 *wait(S)*의 경우, 인터럽트 없이 실행되어야만 한다. 5.6.2절에서 이 operation들이 어떻게 구현되는지 볼 것이다. 우선, 세마포어가 어떻게 사용되는지 보자.

## 5.6.1 Semaphore Usage
---

os는 종종 counting semaphore와 binary semaphore를 구분한다. `counting semaphore`는 제한되지 않은 도메인의 범위를 벗어날 수 있다. `binary semaphore`는 0과 1의 범위만을 갖는다. 그러므로 binary semaphore는 mutex lock과 비슷하게 행동한다. 사실 mutex lock을 지원하지 않는 시스템에서 binary semaphore는 mutex exclusion 대신에 사용될 수 있다.

counting semaphore는 유한 숫자의 인스턴스로 구성된 주어진 자원에 접근하는 것을 제어하기 위해서 사용된다. 세마포어는 이용 가능한 자원의 수로 초기화 된다. 자원을 사용하기 원하는 각 프로세스는 세마포어에 *wait()* operation을 수행한다(숫자가 감소한다). 프로세스가 자원을 반환할 때 *signal()* operation을 실행한다(숫자가 증가한다). 세마포어 숫자가 0이 되면 모든 자원이 사용 중이라는 것이다. 그 후, 자원을 사용하기 원하는 프로세스들은 세마포어 숫자가 0보다 커질 때까지 차단된다.

또한, various synchronization problem을 해결하기 위해서 세마포어가 사용될 수 있다. 예를 들어, 동시에 실행되고 있는 프로세스를 생각하자. S1 statement를 가진 P1과 S2 statement를 가진 P2가 있다. S2는 S1이 완료된 후에만 실행된다. P1과 P2가 0으로 초기화된 common semaphore인 *synch*를 공유하게 함으로써 이 스키마를 손쉽게 구현할 수 있다. 프로세스 P1에
	
	S1;
	signal(synch);

statement를 삽입하고, 프로세스 P2에

	wait(synch);
	S2;

을 삽입한다. synch가 0으로 초기화 되기 때문에 P2는 P1이 *signal(synch)*을 실행한 후에만 실행될 것이다. 즉, S1 statement가 실행되고 나서 실행된다.

## 5.6.2 Semaphores Implementation
---

5.5절에서 논의한 mutex lock의 구현을 생각해보자. 이것은 busy waiting으로 인해 어려움을 겪는다. *wait()*, *signal()* semaphore operation의 정의는 같은 문제를 설명할 뿐이다. 이를 극복하기 위해서 *wait()*와 *signal()* operation의 정의를 다음과 같이 수정할 수 있다. 프로세스가 *wait()* operation을 실행하고 세마포어 값이 양수가 아님을 알게 된다면 프로세스는 기다려야만 한다. 하지만 프로세스는 busy waiting에 참여하기 보다는 자신을 차단한다. 이 block operation은 프로세스를 세마포어와 연관된 waiting queue에 위치시킨다. 그리고 프로세스의 상태는 waiting state로 전환된다. 그러면 제어권이 CPU 스케쥴러에게 넘어가고 CPU 스케쥴러는 다른 프로세스를 실행하기 위해 선택한다.

세마포어 *S*를 기다리고 있는, 차단된 프로세스는 다른 프로세스가 *signal()* operation을 실행할 때 재시작되어야 한다. 프로세스가 *wakeup()* operation에 의해 재시작 되면, 프로세스의 상태가 waiting state에서 ready state로 바뀌게 된다. 그러면 프로세스는 ready queue에 위치하게 된다. (CPU는 실행 중인 프로세스에서 새롭게 준비된 프로세스로 전환될 수 있고 아닐 수 있다. 이것은 CPU 스케쥴링 알고리즘에 따른다.)

이 정의 하에 세마포어를 구현하기 위해서 세마포어를 다음과 같이 정의 한다.

	typedef struct{
		int value;
		struct process *list;
	} semaphore;

각 세마포어는 *value*와 프로세스의 리스트 *list*를 가지고 있다. 프로세스가 세마포어를 기다려야만 할 때, 프로세스는 리스트에 추가된다. *signal()* operation은 기다리고 있는 프로세스의 리스트에서 한 프로세서를 제거하고, 대기 중인 상태를 깨뜨린다.

이제 *wait()* semaphore operation은 다음과 같이 정의될 수 있다. 

	wait(semaphore *S){
		S->value--;
		if(S->value < 0){
			add this process to S->list;
			block();
		}
	}	

그리고 *signal()* semaphore operation은 다음과 같이 정의될 수 있다.

	signal(semaphore *S){
		S->value++;
		if(S->value <= 0){
			remove a process P from S->list;
			wakeup(P);
		}
	}

*block()* operation은 *wait()*를 호출하는 프로세스를 중단한다. *wakeup(P)* operation은 차단된 프로세스 *P*의 실행을 재개한다. 이 두 operation은 basic system call로서 os의해 제공된다.

이 구현에서 세마포어 값은 음수가 될 수 있는 반면, busy waiting을 갖고 있는 고전적인 세마포어의 정의는 절대 음수가 될 수 없다. 세마포어의 값이 음수가 된다면 이 값은 해당 세마포어를 기다리고 있는 프로세스의 수 크기를 나타낸다. 이것은 *wait()* operation의 구현에서 test(if)와 감산의 순서가 바뀐 결과다.

기다리고 있는 프로세스의 리스트는 각 process control block(PCB)의 link field에 의해 쉽게 구현될 수 있다. 각 세마포어는 정수 값과 PCB를 가리키는 포인터를 포함한다. bounded waiting을 보장하기 위해 리스트에 프로세스를 추가하거나 제거하는 한 방법은 FIFO 큐를 사용하는 것이다. 세마포어는 이 큐를 가리키는 head와 tail을 가리키는 포인터를 포함한다. 그러나 일반적으로 이 리스트는 큐 전략에 사용된다. 세마포어의 옳은 사용법은, 세마포터 리스트를 위한 특정 큐 전략에 의존하지 않는다.

semaphore operation이 atomically하게 실행되는 것은 중요하다. 두 개의 프로세스가 같은 시간에 같은 세마포어의 *wait()*, *signal()* operation을 사용하지 못하게 보장해야만 한다. 이것은 critical-section problem이다. 그리고 single-processor 환경에서, 이것은 *wait()*, *signal()* operation이 실행되는 동안 인터럽트를 간단히 억제하는 것을 통해서 해결이 가능하다. 인터럽트가 억제되면 다른 프로세스의 instruction은 interleave될 수 없기 때문에, 이 스키마는 single-processor 환경에서 동작한다. 현재 실행 중인 프로세스는 인터럽트가 다시 이용 가능해지고 스케쥴러가 제어권을 다시 얻게 될 때까지 실행된다. multiprocessor 환경에서 인터럽트는 모든 프로세서에서 이용 불가능해야 한다. 그렇지 않으면 다른 프로세스(다른 프로세서에서 실행 중인)의 instruction은 임의의 방식으로 interleve될 것이다. 모든 프로세서에서 인터럽트를 제한하는 것은 어려운 태스크가 될 수 있고 성능이 심각하게 저하될 수 있다. 그러므로 SMP 시스템은, *compare_and_swap()* 또는 *spinlock* 처럼 *wait()*, *signal()*이 atomically하게 수행되도록 보장하는 대안적인 locking 기술을 제공해야 한다.

*wait()*, *signal()* operation의 정의와 함께 busy waiting을 완전히 제거하지 않았다는 것을 받아들이는 것은 중요하다. 오히려 busy waiting을 entry section에서 어플리케이션 프로그램의 critical section으로 옮겼다. 게다가 *wait()*, *signal()* operation에 대한 critical section에 대한 busy waiting을 제한했다. 그리고 이 section은 짧다(적절히 코딩되었으면, 10개 정도의 instruction보다 적다). 그러므로 critical section은 절대 점유되지 않는다. 그리고 busy waiting은 드물게 발생하고 잠깐 동안만 유지된다. 이와는 완전히 다른 상황은 critical section의 길이가 분 단위, 심지어 시간 단위로 길어지거나, 항상 점유 되고 있는 어플리케이션 프로그램에서 존재한다. 이런 경우 busy waiting은 매우 비효율적이다.

## 5.6.3 Deadlocks and Starvation
---

waiting queue처럼 세마포어를 구현하는 것은 두 개 이상의 프로세스가, 대기 중인 하나의 프로세스에 의해 발생하는 이벤트를 무한정 기다리는 상황을 일으킨다. 의심이 가는 이벤트는 *signal()* operation의 실행이다. 이런 상태가 되면 이 프로세스는 `deadlock`이 되었다고 말한다.

이것을 설명하기 위해서 두 프로세스 P0, P1로 구성된 시스템을 생각해보자. 각 프로세스는 두 개의 세마포어 S, Q의 값을 1로 설정하고 엑세스 한다.

	P0				P1
	wait(S);		wait(Q);
	wait(Q);		wait(S);
	.				.
	.				.
	.				.
	signal(S);		signal(Q);
	signal(Q);		signal(S);

P0이 *wait(S)*를 실행하면 P1이 *wait(Q)*를 실행한다고 가정해보자. P0이 *wait(Q)*를 실행하면 이것은 P1이 *signal(Q)*를 실행하기를 기다려야만 한다. 유사하게, P1이 *wait(S)*를 실행하면 이것은 P0이 *signal(S)*를 실행하기를 기다려야 한다. *signal()* operation이 실행될 수 없기 때문에 P0와 P1은 데드락에 걸린다.

한 집합의 모든 프로세스가 같은 집합의 다른 프로세스에 의해 일어날 수 있는 이벤트를 기다릴 때, 프로세스 집합이 데드락 상태라고 말한다. 여기에서 주된 관심을 받는 이벤트는 자원을 할당받고 반환하는 것이다. 7장에서 보겠지만 다른 종류의 이벤트도 데드락 상태를 야기할 수 있다. 이번 장에서는 deadlock problem을 다루는 다양한 메커니즘을 설명한다.

데드락과 관련된 다른 문제는 `indefinite blocking` 또는 `starvation`이다. 이것들은 세마포어 안에서 프로세스가 무한정 기다리는 상태를 말한다. 무한정 차단되는 것은 우리가 세마포어와 연관된 리스트에서 LIFO 순서로 프로세스를 제거할 때 발생할 수 있다.

## 5.6.4 Priority Inversion
---

높은 우선순위 프로세스가, 낮은 우선순위 프로세스나 그 chain에 의해 엑세스 되고 있는 커널 데이터를 읽거나 수정하려할 때 스케쥴링 문제가 발생한다. 커널 데이터는 lock으로 보호되기 때문에 높은 우선순위 프로세스는 낮은 우선순위 프로세스가 자원의 사용을 마칠 때까지 기다려야만 한다. 이 상황은 낮은 우선순위 프로세스가 다른 높은 우선순위 프로레스보다 먼저 선점될 때 더 복잡해진다.

한 가지 예로, 세 개의 프로세스 L, M, H가 있고 우선 순위는 L < M < H라 하자. 프로세스 H가 현재 L에 의해 엑세스 되고 있는 자원 R을 요구한다고 가정하자. 일반적으로 프로세스 H는 자원 R을 사용하는 프로세스 L이 끝날 때까지 기다려야 한다. 하지만 이제 프로세스 M이 실행가능하게 되어 프로세스 L을 선점한다고 가정하자. 간접적으로, 낮은 우선순위 프로세스를 갖는 프로세스 M은 프로세스 H가 프로세스 L이 자원을 포기하는데 기다려야 하는 시간에 영향을 준다.

이 문제는 `priority inversion`으로 알려졌다. 이것은 두 개 보다 많은 우선순위를 가진 시스템에서 발생한다. 그래서 한 가지 솔루션은 오직 두 개의 우선순위만을 갖도록 하는 것이다. 하지만 이것은 general-purpose os에게 적합하지 않다. 일반적으로 이런 시스템들은 `priority-inheritance protocol`을 구현함으로써 이 문제를 해결한다. 이 프로토콜에 따르면, 높은 우선순위에 의해 필요되는 자원에 접근하려는 모든 프로세스는, 문제의 자원 사용을 마칠 때까지 앞의 높은 우선순위를 상속 받는다. 프로세스가 일을 마치면 프로세스의 우선순위는 원래 값으로 되돌아 간다. 위의 예에서 priority-inheritance protocol은 프로세스 L에게 임시적으로 프로세스 H의 우선순위를 상속한다. 이로써 프로세스 M에 의한 실행 선점을 예방할 수 있다. 프로세스 L이 자원 R의 사용을 마치면 프로세스 H로부터 상속 받았던 우선순위를 포기하고 원래의 우선순위로 되돌아온다. 자원 R은 이제 이용 가능한 상태이기 때문에 프로세스 M이 아닌 프로세스 H가 다음에 실행된다.

	*PRIORITY INVERSION AND THE MARS PATHFINDER*
	priority inversion은 스케쥴링보다 더 불편할 수 있다. real-time 시스템과 같이 타이트한 시간 제약이 있는 시스템에서는, priority inversion이 일을 완수하는것 보다 시간을 잡아먹는 프로세스를 발생시킬 수 있다. 이것이 발생하면 연쇄적으로 다른 실패가 발생할 수 있으며 결과적으로 시스템이 실패하게 된다.

	실험을 위해서 나사의 탐사선 Mars Pathfinder를 생각하자. 탐사선이 동작을 시작한 후 잠깐 동안, 자주 컴퓨터를 리셋하는 일이 발생했다. 각 리셋은 통신을 포함한 모든 하드웨어와 소프트웨어를 다시 초기화 했다. 이 문제가 해결되지 않았다면 탐사선은 임무를 실패했을 것이다.

	이 문제는 높은 우선순위를 가진 작업 "bc_dist"가 작업을 완수하는데 예상보다 오랜 시간을 사용했기 때문에 발생했다. 이 작업은 낮은 우선순위를 갖은 "ASI/MET" 작업에 의해 사용 중인 공유 자원을 강제로 기다려야 했고, "ASI/MET"은 많은 중간 우선순위 작업에 의해 선점 되었다.
	"bc_dist" 작업은 공유된 자원을 기다리도록 지연시켰을 것이고 궁극적으로 "bc_sched" 작업은 문제를 발견하고 리셋을 수행했을 것이다. 탐사선은 priority inversion의 일반적인 케이스에 놓여 있었다. 
	탐사선의 os는 VxWorks real-time os였고, 이것은 모든 세마포어에 우선순위 상속을 가능하게 하는 전역변수를 가지고 있었다. 테스트 후, 전역 변수는 탐사선에 설정되었고 문제는 해결되었다.
	이 문제의 발견, 솔루션, 전체 내용은 소프트웨어 팀이 작성했으며 이는 http://reserach.microsoft.com/en-us/um/people/mbj/mars_pathfinder/authoritative_account.html에서 이용 가능하다.
