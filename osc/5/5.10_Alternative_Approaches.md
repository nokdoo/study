# 5.10 Alternative Approaches
---

multicore system의 출현으로 multiple processing core의 장점을 취하기 위해 멀티스레딩 어플리케이션 개발에 대한 압박이 증가했다. 하지만 멀티스레딩 어플리케이션은 race condition과 deadlock의 위험을 증가 시킨다. 전통적으로 mutex lock, semaphore, monitor와 같은 기술은 이런 이슈를 다루기 위해 사용되었다. 하지만 processing core 수의 증가로 인해 이것은 race condition과 deadlock으로 부터 자유로운 어플리케이션을 설계하는데 어려움을 증가시켰다. 이번 절에서는 프로그래밍 언어와 thread-safe concurrent application 설계를 지원하는 하드웨어의 다양한 특징을 다룬다.

## 5.10.1 Transactional Memory
---

CS 분야에서는 연구의 한 영역에서 나온 생각을 다른 영역의 문제를 해결하기 위해 꽤 자주 사용될 수 있다. 예로, `transactional memory`의 개념은 데이터베이스 이론에서 유래되었지만 이것은 process synchronization에 대한 전략을 제공한다. `memory transaction`은 atomic한 memory read-write operation의 시퀀스이다. transaction에서 모든 operation이 완료되면 memory transaction은 커밋된다. 그렇지 않으면 operation들은 중단, 롤백되어야 한다. transactional memory의 장점은 프로그래밍 언어에 추가된 기능을 통해 얻을 수 있다.

한 예를 생각해보자. 공유된 데이터를 수정하는 *update()* 함수가 있다고 가정한다. 전통적으로 이 함수는 다음과 같이 mutex lock 또는 semaphore를 이용하여 작성되었을 것이다.

	void update()
	{
		acquire();

		/* modify shared data */

		release();
	}

하지만 mutex lock이나 semaphore 같은 synchronization mechanism은 데드락과 같은 많은 잠재적 문제를 포함한다. 추가적으로 스레드의 수가 증가함에 따라 전통적인 locking의 규모는 줄어들었다. 스레드 간 lock 소유권을 위한 경쟁이 더 심해졌기 때문이다.

전톡적인 locking 방법의 대안으로 transaction memory의 장점을 취하는 새로운 특징이 프로그래밍 언어에 추가되었다. 여기에서는 S의 operation이 transaction으로서 실행을 보장하는 construct *atomic{S}*를 추가한다고 가정한다. 이것은 *update()*함수를 다음과 같이 재작성할 수 있게 해준다.

	void update()
	{
		atomic{
			/* modify shared data */
		}
	}

lock대신 mechanism을 사용하는 이점은 개발자가 아닌 transactional memory system이 atomicity를 보장한다는 것이다. 추가적으로 lock이 포함되지 않기 때문에 데드락의 가능성이 없다. 게다가 transactional memory system은, 공유된 변수에 동시에 read access하는 것처럼 atomic block에서 동시에 실행될 수 있는 statement를 식별할 수 있다. 물론 프로그래머를 위해 이런 상황을 식별하고 reader-wrtier lock을 사용하는 것은 가능하다. 하지만 어플리케이션 내의 스레드의 수가 증가함에 따라 태스크는 점차적으로 어려워진다.

transactional memory는 소프트웨어 또는 하드웨어에서 구현될 수 있다. `Software transactional memory`(STM)은 이름에서 알 수 있듯이, 특별한 하드웨어가 필요 없이 소프트웨어에서 transactional memory만을 구현한다. 코드는 컴파일러에 의해서 삽입되고, statement가 동시에 실행 가능한지 특정한 low-level locking이 요구되는지를 검사함으로써 각 transaction을 관리한다. `Hardware transactional memory`(HTM)은 별도의 processor cache에 위치하고 있는 공유된 데이터를 포함하는 충돌을 관리하고 해결하기 위해 hardware cache hierarchies와 cache coherency protocol을 사용한다. HTM은 특정 code instrumentation을 요구하지 않으므로 STM보다 오버헤드가 적다. 하지만 HTM은 존재하고 있는 cache hierarchies와 cache coherency protocol이 transactional memory를 지원하기 위해 수정될 것을 요구한다.

transactional memory는 광범위한 구현 없이 몇 년간 존재해왔다. 하지만 multicore system의 성장과 concurrent, parallel programming과 관련된 중요성의 성장은 academic, commercial software, hardware vendor 모두에게 이 분야에 대한 상당한 연구를 촉진했다.

## 5.10.2 OpenMP
---

4.5.2절에서 OpenMP의 개요와 이것이 shared-memory environmen에서 병렬 프로그래밍을 지원하는 것을 보았다. OpenMP는 compiler directive와 API의 집합을 포함하는 것을 기억하자. compiler directive *#pragma omp parallel*는 parallel region으로서 식별되고, 시스템의 processing core와 같은 수의 스레드에 의해서 수행된다. OpenMP의 이점은 스레드 생성과 관리는 OpenMP library에 의해서 핸들링되고, 어플리케이션 개발자에게 책임이 없다는 것이다.

OpenMP는 *#pragma omp parallel* compiler directive와 함께 *#pragma omp critical*을 제공하는데, 이것은 같은 시간에 오직 하나의 스레드만 활성화 될 수 있는 critical section으로서 directive 다음에 오는 코드 영역을 명시한다. 이 방법으로 OpenMP는 race condition을 생성하지 않는 스레드를 확보하기 위한 지원을 제공한다.

critical-section compiler directive의 사용의 예로, 먼저 공유된 변수 *counter*가 *update()* 함수 에서 다음과 같이 수정될 수 있음을 가정하자.

	void update(int value)
	{
		counter += value;
	}

*update()* 함수가 parallel region의 일부가 되거나 parallel region으로 부터 호출될 수 있다면, *counter* 변수에서 race condition의 가능성이 있다.

critical-section compiler directive는 이런 race condition을 고치는데 사용될 수 있고 코드는 다음과 같다

	void update(int value)
	{
		#pragma omp critical
		{
			counter += value;
		}
	}

critical-section compiler directive는, critical section에서 같은 시간에 오직 하나의 스레드만 활성되는 것을 보장하는 binary semaphore 또는 mutex lock처럼 행동한다. 스레드가 현재 자신의 critical section에서 활성화되고 있을 때 다른 스레드가 critical section으로 진입하는 것을 시도한다면. 스레드를 호출하는 것은, 이미 활성화된 스레드가 종료될 때까지 차단된다. Multiple critical section이 사용되어야만 한다면 각 critical section은 별도의 이름이 할당될 수 있고, 이 규칙은 같은 이름의 critical section 스레드가 동시에 2개 이상 활성화 되지 않는 것을 명시한다.

OpenMP에서 critical-section compiler directive를 사용하는 것의 이점은 일반적으로 표준 mutex lock보다 사용이 쉽다는 것이다. 하지만 단점은 여전히 어플리케이션 개발자가 race condition의 가능성을 식별해야만 한다는 것과 compiler directive를 사용하여 공유된 데이터를 적절하게 보호해야한다는 것이다. 추가적으로 critical-section compiler directive는 mutex lock처럼 행동하기 때문에 두 개 이상의 critical section이 식별될 때 여전히 데드락의 가능성이 존재한다.

## 5.10.3
---

C, C++, Java, C#처럼 잘 알려진 프로그래밍 언어는 `imperative`(또는 `procedural`) 언어로 알려져 있다. imperative 언어는 state-based인 알고리즘을 구현하기 위해서 사용된다. 이런 언어에서 알고리즘의 흐름은 옳은 operation을 위해서 결정적이다. 그리고 state는 variable과 다른 data structure와 함께 표현된다. 물론 변수가 시간이 지남에 따라 다른 값으로 할당될 수 있는 것처럼 프로그램 state는 mutable이다.

현재의 multicore system을 위한 concurrent와 parallel 프로그래밍 강조로 `functional` 프로그래밍 언어에 많은 관심이 있었다. 이 언어는 imperative 언어에 의해 제공된 것과는 많이 다른 프로그래밍 패러다임을 따른다. imperative과 functional 언어의 근본적인 차이점은, functional 언어는 state를 관리하지 않는다는 것이다. 이것은 변수가 한 번 정의되고 값이 할당되면 그 값은 immutable이라는 것이다. functional 언어가 mutable state를 허용하지 않기 때문에 race condition, deadlock과 같은 이슈를 고려할 필요가 없다. 본질적으로, 이 장에서 다루는 대부분의 문제는 functional 언어에 존재하지 않는다.

몇 가지 functional 언어는 현재 사용중이다. 그리고 이들 중 두 가지, Erlang과 Scala를 간략히 언급한다. Erlang 언어는 concurrency에 대한 지원과, parallel system에서 실행되는 어플리케이션을 개발하는데 사용될 수 있는 용이함 때문에 상단한 관심을 받았다. Scala는 object-oriented functional 언어이다. 사실 Scala의 대부분 문법은 인기있는 object-oriented 언어, Java C#과 유사하다. Erlang과 Scala, 일반적인 functional 언어에 대한 관심을 가지고 있다면 이 장의 끝에 추가적인 참조를 위한 참고문헌을 찾아보기를 권장한다.
